Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='Autoformer', model_id='ili_36_36', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=36, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ili_36_36_Autoformer_custom_ftM_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 605
val 62
test 158
Epoch: 1 cost time: 2.3747200965881348
Epoch: 1, Steps: 4 | Train Loss: 1.4178131 Vali Loss: nan Test Loss: 4.7779703
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.2514028549194336
Epoch: 2, Steps: 4 | Train Loss: 1.4603017 Vali Loss: nan Test Loss: 4.4215198
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.2749969959259033
Epoch: 3, Steps: 4 | Train Loss: 1.1334502 Vali Loss: nan Test Loss: 4.2249365
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.363158941268921
Epoch: 4, Steps: 4 | Train Loss: 1.0530236 Vali Loss: nan Test Loss: 4.0222077
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.4451024532318115
Epoch: 5, Steps: 4 | Train Loss: 0.9580923 Vali Loss: nan Test Loss: 3.8747065
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.511845111846924
Epoch: 6, Steps: 4 | Train Loss: 0.9074177 Vali Loss: nan Test Loss: 3.7596171
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.381608724594116
Epoch: 7, Steps: 4 | Train Loss: 0.8400404 Vali Loss: nan Test Loss: 3.6974838
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.3856520652770996
Epoch: 8, Steps: 4 | Train Loss: 0.8121871 Vali Loss: nan Test Loss: 3.6562474
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.5020532608032227
Epoch: 9, Steps: 4 | Train Loss: 0.7889600 Vali Loss: nan Test Loss: 3.6102276
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.4346225261688232
Epoch: 10, Steps: 4 | Train Loss: 0.7538096 Vali Loss: nan Test Loss: 3.5727863
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.446171760559082
Epoch: 11, Steps: 4 | Train Loss: 0.7228165 Vali Loss: nan Test Loss: 3.5383122
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.1935830116271973
Epoch: 12, Steps: 4 | Train Loss: 0.7073206 Vali Loss: nan Test Loss: 3.5109351
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.3638269901275635
Epoch: 13, Steps: 4 | Train Loss: 0.6743261 Vali Loss: nan Test Loss: 3.4756682
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.316653251647949
Epoch: 14, Steps: 4 | Train Loss: 0.6605152 Vali Loss: nan Test Loss: 3.4355779
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.409459114074707
Epoch: 15, Steps: 4 | Train Loss: 0.6752082 Vali Loss: nan Test Loss: 3.3985918
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.352095127105713
Epoch: 16, Steps: 4 | Train Loss: 0.6713167 Vali Loss: nan Test Loss: 3.3655367
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.3459384441375732
Epoch: 17, Steps: 4 | Train Loss: 0.6523304 Vali Loss: nan Test Loss: 3.3295135
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.235006332397461
Epoch: 18, Steps: 4 | Train Loss: 0.6237130 Vali Loss: nan Test Loss: 3.2992306
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.2426040172576904
Epoch: 19, Steps: 4 | Train Loss: 0.6098748 Vali Loss: nan Test Loss: 3.2709215
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.421250820159912
Epoch: 20, Steps: 4 | Train Loss: 0.6243991 Vali Loss: nan Test Loss: 3.2389772
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.3288373947143555
Epoch: 21, Steps: 4 | Train Loss: 0.6152630 Vali Loss: nan Test Loss: 3.2142987
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.1838109493255615
Epoch: 22, Steps: 4 | Train Loss: 0.5900092 Vali Loss: nan Test Loss: 3.1900182
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.31858229637146
Epoch: 23, Steps: 4 | Train Loss: 0.5869295 Vali Loss: nan Test Loss: 3.1703012
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.3264479637145996
Epoch: 24, Steps: 4 | Train Loss: 0.5856955 Vali Loss: nan Test Loss: 3.1526053
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.4640674591064453
Epoch: 25, Steps: 4 | Train Loss: 0.5790935 Vali Loss: nan Test Loss: 3.1438160
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.1319587230682373
Epoch: 26, Steps: 4 | Train Loss: 0.5677448 Vali Loss: nan Test Loss: 3.1354783
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.31921124458313
Epoch: 27, Steps: 4 | Train Loss: 0.5662677 Vali Loss: nan Test Loss: 3.1266236
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.309288501739502
Epoch: 28, Steps: 4 | Train Loss: 0.5687569 Vali Loss: nan Test Loss: 3.1162238
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.270106792449951
Epoch: 29, Steps: 4 | Train Loss: 0.5722256 Vali Loss: nan Test Loss: 3.1099727
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.310147285461426
Epoch: 30, Steps: 4 | Train Loss: 0.5699886 Vali Loss: nan Test Loss: 3.1002259
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.0592691898345947
Epoch: 31, Steps: 4 | Train Loss: 0.5694175 Vali Loss: nan Test Loss: 3.0953720
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.0889554023742676
Epoch: 32, Steps: 4 | Train Loss: 0.5525012 Vali Loss: nan Test Loss: 3.0907428
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.263296604156494
Epoch: 33, Steps: 4 | Train Loss: 0.5914989 Vali Loss: nan Test Loss: 3.0846815
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.29246187210083
Epoch: 34, Steps: 4 | Train Loss: 0.5544649 Vali Loss: nan Test Loss: 3.0812309
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.3552088737487793
Epoch: 35, Steps: 4 | Train Loss: 0.5519310 Vali Loss: nan Test Loss: 3.0769606
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.3764116764068604
Epoch: 36, Steps: 4 | Train Loss: 0.5532996 Vali Loss: nan Test Loss: 3.0737584
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.164996862411499
Epoch: 37, Steps: 4 | Train Loss: 0.5710380 Vali Loss: nan Test Loss: 3.0717375
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.0806968212127686
Epoch: 38, Steps: 4 | Train Loss: 0.5530847 Vali Loss: nan Test Loss: 3.0712271
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.281928062438965
Epoch: 39, Steps: 4 | Train Loss: 0.5824798 Vali Loss: nan Test Loss: 3.0693393
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.344289541244507
Epoch: 40, Steps: 4 | Train Loss: 0.5518854 Vali Loss: nan Test Loss: 3.0653200
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.2823846340179443
Epoch: 41, Steps: 4 | Train Loss: 0.5559022 Vali Loss: nan Test Loss: 3.0640626
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.3383471965789795
Epoch: 42, Steps: 4 | Train Loss: 0.5396575 Vali Loss: nan Test Loss: 3.0616720
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 2.3344016075134277
Epoch: 43, Steps: 4 | Train Loss: 0.5549005 Vali Loss: nan Test Loss: 3.0605652
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 2.276492118835449
Epoch: 44, Steps: 4 | Train Loss: 0.5535251 Vali Loss: nan Test Loss: 3.0584316
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 2.2948484420776367
Epoch: 45, Steps: 4 | Train Loss: 0.5518117 Vali Loss: nan Test Loss: 3.0544033
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 2.309499979019165
Epoch: 46, Steps: 4 | Train Loss: 0.5572355 Vali Loss: nan Test Loss: 3.0530336
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.2745704650878906
Epoch: 47, Steps: 4 | Train Loss: 0.5542258 Vali Loss: nan Test Loss: 3.0522153
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 2.3769986629486084
Epoch: 48, Steps: 4 | Train Loss: 0.5501237 Vali Loss: nan Test Loss: 3.0495639
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 2.3727877140045166
Epoch: 49, Steps: 4 | Train Loss: 0.5604717 Vali Loss: nan Test Loss: 3.0488217
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 2.3721511363983154
Epoch: 50, Steps: 4 | Train Loss: 0.5514679 Vali Loss: nan Test Loss: 3.0489869
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.3073513507843018
Epoch: 51, Steps: 4 | Train Loss: 0.5451913 Vali Loss: nan Test Loss: 3.0478652
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.333507537841797
Epoch: 52, Steps: 4 | Train Loss: 0.5381569 Vali Loss: nan Test Loss: 3.0477057
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.2072553634643555
Epoch: 53, Steps: 4 | Train Loss: 0.5502247 Vali Loss: nan Test Loss: 3.0476108
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 2.342651128768921
Epoch: 54, Steps: 4 | Train Loss: 0.5564817 Vali Loss: nan Test Loss: 3.0469980
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 2.3710644245147705
Epoch: 55, Steps: 4 | Train Loss: 0.5427218 Vali Loss: nan Test Loss: 3.0466242
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.429962635040283
Epoch: 56, Steps: 4 | Train Loss: 0.5421734 Vali Loss: nan Test Loss: 3.0461698
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 2.2861945629119873
Epoch: 57, Steps: 4 | Train Loss: 0.5435183 Vali Loss: nan Test Loss: 3.0460401
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 2.277256727218628
Epoch: 58, Steps: 4 | Train Loss: 0.5607619 Vali Loss: nan Test Loss: 3.0458536
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 2.3776373863220215
Epoch: 59, Steps: 4 | Train Loss: 0.5488225 Vali Loss: nan Test Loss: 3.0450997
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 2.320180892944336
Epoch: 60, Steps: 4 | Train Loss: 0.5504927 Vali Loss: nan Test Loss: 3.0449634
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 2.244184732437134
Epoch: 61, Steps: 4 | Train Loss: 0.5345181 Vali Loss: nan Test Loss: 3.0447369
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 2.3870396614074707
Epoch: 62, Steps: 4 | Train Loss: 0.5423950 Vali Loss: nan Test Loss: 3.0446219
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 2.3276355266571045
Epoch: 63, Steps: 4 | Train Loss: 0.5299031 Vali Loss: nan Test Loss: 3.0445213
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 2.277740955352783
Epoch: 64, Steps: 4 | Train Loss: 0.5544138 Vali Loss: nan Test Loss: 3.0447693
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.2634615898132324
Epoch: 65, Steps: 4 | Train Loss: 0.5459358 Vali Loss: nan Test Loss: 3.0446472
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 2.3793017864227295
Epoch: 66, Steps: 4 | Train Loss: 0.5340420 Vali Loss: nan Test Loss: 3.0445509
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.382129430770874
Epoch: 67, Steps: 4 | Train Loss: 0.5496371 Vali Loss: nan Test Loss: 3.0442736
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 2.2170422077178955
Epoch: 68, Steps: 4 | Train Loss: 0.5385592 Vali Loss: nan Test Loss: 3.0443633
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 2.200875759124756
Epoch: 69, Steps: 4 | Train Loss: 0.5233298 Vali Loss: nan Test Loss: 3.0443149
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.3978652954101562
Epoch: 70, Steps: 4 | Train Loss: 0.5272507 Vali Loss: nan Test Loss: 3.0446210
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 2.2673237323760986
Epoch: 71, Steps: 4 | Train Loss: 0.5398765 Vali Loss: nan Test Loss: 3.0445781
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.3650522232055664
Epoch: 72, Steps: 4 | Train Loss: 0.5430502 Vali Loss: nan Test Loss: 3.0445340
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 2.2795259952545166
Epoch: 73, Steps: 4 | Train Loss: 0.5494317 Vali Loss: nan Test Loss: 3.0441442
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.4029502868652344
Epoch: 74, Steps: 4 | Train Loss: 0.5499667 Vali Loss: nan Test Loss: 3.0441000
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 2.31752872467041
Epoch: 75, Steps: 4 | Train Loss: 0.5492795 Vali Loss: nan Test Loss: 3.0440679
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 2.3583121299743652
Epoch: 76, Steps: 4 | Train Loss: 0.5553819 Vali Loss: nan Test Loss: 3.0440352
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 2.4316792488098145
Epoch: 77, Steps: 4 | Train Loss: 0.5608201 Vali Loss: nan Test Loss: 3.0438466
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 2.1812732219696045
Epoch: 78, Steps: 4 | Train Loss: 0.5446136 Vali Loss: nan Test Loss: 3.0438206
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 2.1821913719177246
Epoch: 79, Steps: 4 | Train Loss: 0.5425950 Vali Loss: nan Test Loss: 3.0437980
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.2931535243988037
Epoch: 80, Steps: 4 | Train Loss: 0.5292069 Vali Loss: nan Test Loss: 3.0439320
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 2.353931427001953
Epoch: 81, Steps: 4 | Train Loss: 0.5459478 Vali Loss: nan Test Loss: 3.0443377
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.084127426147461
Epoch: 82, Steps: 4 | Train Loss: 0.5459959 Vali Loss: nan Test Loss: 3.0441623
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 2.297755479812622
Epoch: 83, Steps: 4 | Train Loss: 0.5557760 Vali Loss: nan Test Loss: 3.0443013
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 2.297811985015869
Epoch: 84, Steps: 4 | Train Loss: 0.5458185 Vali Loss: nan Test Loss: 3.0442879
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 2.3595099449157715
Epoch: 85, Steps: 4 | Train Loss: 0.5151502 Vali Loss: nan Test Loss: 3.0442812
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 2.16159725189209
Epoch: 86, Steps: 4 | Train Loss: 0.5413443 Vali Loss: nan Test Loss: 3.0442741
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.198798418045044
Epoch: 87, Steps: 4 | Train Loss: 0.5442811 Vali Loss: nan Test Loss: 3.0442655
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 2.290583610534668
Epoch: 88, Steps: 4 | Train Loss: 0.5571155 Vali Loss: nan Test Loss: 3.0442562
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.38082218170166
Epoch: 89, Steps: 4 | Train Loss: 0.5594567 Vali Loss: nan Test Loss: 3.0442526
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 2.4771039485931396
Epoch: 90, Steps: 4 | Train Loss: 0.5392044 Vali Loss: nan Test Loss: 3.0442817
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 2.361856460571289
Epoch: 91, Steps: 4 | Train Loss: 0.5532852 Vali Loss: nan Test Loss: 3.0442772
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 2.375960350036621
Epoch: 92, Steps: 4 | Train Loss: 0.5548945 Vali Loss: nan Test Loss: 3.0442755
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.374940872192383
Epoch: 93, Steps: 4 | Train Loss: 0.5552576 Vali Loss: nan Test Loss: 3.0442760
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 2.3425610065460205
Epoch: 94, Steps: 4 | Train Loss: 0.5299847 Vali Loss: nan Test Loss: 3.0442762
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.267958879470825
Epoch: 95, Steps: 4 | Train Loss: 0.5494600 Vali Loss: nan Test Loss: 3.0442724
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 2.2738397121429443
Epoch: 96, Steps: 4 | Train Loss: 0.5473685 Vali Loss: nan Test Loss: 3.0442708
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.4623453617095947
Epoch: 97, Steps: 4 | Train Loss: 0.5188809 Vali Loss: nan Test Loss: 3.0442681
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 2.24163818359375
Epoch: 98, Steps: 4 | Train Loss: 0.5313712 Vali Loss: nan Test Loss: 3.0442655
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 2.128633737564087
Epoch: 99, Steps: 4 | Train Loss: 0.5314899 Vali Loss: nan Test Loss: 3.0442641
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 2.415573835372925
Epoch: 100, Steps: 4 | Train Loss: 0.5170486 Vali Loss: nan Test Loss: 3.0442638
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : ili_36_36_Autoformer_custom_ftM_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
mse:3.0442636013031006, mae:1.154632806777954, rse:0.8435213565826416
