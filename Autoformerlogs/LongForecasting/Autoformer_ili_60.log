Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='Autoformer', model_id='ili_36_60', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=60, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ili_36_60_Autoformer_custom_ftM_sl36_ll18_pl60_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 581
val 38
test 134
Epoch: 1 cost time: 2.3587794303894043
Epoch: 1, Steps: 4 | Train Loss: 1.4007051 Vali Loss: nan Test Loss: 4.8306708
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.3310980796813965
Epoch: 2, Steps: 4 | Train Loss: 1.3284114 Vali Loss: nan Test Loss: 4.4942546
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.1395649909973145
Epoch: 3, Steps: 4 | Train Loss: 1.1650207 Vali Loss: nan Test Loss: 4.2758598
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.4225432872772217
Epoch: 4, Steps: 4 | Train Loss: 1.0910594 Vali Loss: nan Test Loss: 4.0983467
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.434084892272949
Epoch: 5, Steps: 4 | Train Loss: 0.9815185 Vali Loss: nan Test Loss: 3.9163737
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.42989444732666
Epoch: 6, Steps: 4 | Train Loss: 0.9077824 Vali Loss: nan Test Loss: 3.8275349
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.380389928817749
Epoch: 7, Steps: 4 | Train Loss: 0.8561345 Vali Loss: nan Test Loss: 3.7605503
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.3412814140319824
Epoch: 8, Steps: 4 | Train Loss: 0.8300840 Vali Loss: nan Test Loss: 3.7172339
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.31786847114563
Epoch: 9, Steps: 4 | Train Loss: 0.7946185 Vali Loss: nan Test Loss: 3.6986244
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.393263339996338
Epoch: 10, Steps: 4 | Train Loss: 0.7662520 Vali Loss: nan Test Loss: 3.6797502
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.3871207237243652
Epoch: 11, Steps: 4 | Train Loss: 0.7413898 Vali Loss: nan Test Loss: 3.6453538
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.3217086791992188
Epoch: 12, Steps: 4 | Train Loss: 0.7257771 Vali Loss: nan Test Loss: 3.6077406
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.399254560470581
Epoch: 13, Steps: 4 | Train Loss: 0.7108476 Vali Loss: nan Test Loss: 3.5719826
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.293696165084839
Epoch: 14, Steps: 4 | Train Loss: 0.7076564 Vali Loss: nan Test Loss: 3.5338378
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.431932210922241
Epoch: 15, Steps: 4 | Train Loss: 0.6559521 Vali Loss: nan Test Loss: 3.4992306
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.3909685611724854
Epoch: 16, Steps: 4 | Train Loss: 0.6909211 Vali Loss: nan Test Loss: 3.4689136
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.2574236392974854
Epoch: 17, Steps: 4 | Train Loss: 0.6688733 Vali Loss: nan Test Loss: 3.4393752
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.3192532062530518
Epoch: 18, Steps: 4 | Train Loss: 0.6486921 Vali Loss: nan Test Loss: 3.4200299
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.3369312286376953
Epoch: 19, Steps: 4 | Train Loss: 0.6475511 Vali Loss: nan Test Loss: 3.4018240
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.3699333667755127
Epoch: 20, Steps: 4 | Train Loss: 0.6588416 Vali Loss: nan Test Loss: 3.3852222
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.431241512298584
Epoch: 21, Steps: 4 | Train Loss: 0.6295712 Vali Loss: nan Test Loss: 3.3699641
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.3325908184051514
Epoch: 22, Steps: 4 | Train Loss: 0.6455960 Vali Loss: nan Test Loss: 3.3556077
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.386493444442749
Epoch: 23, Steps: 4 | Train Loss: 0.6376891 Vali Loss: nan Test Loss: 3.3418438
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.331103563308716
Epoch: 24, Steps: 4 | Train Loss: 0.6365153 Vali Loss: nan Test Loss: 3.3283947
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.4278290271759033
Epoch: 25, Steps: 4 | Train Loss: 0.6231978 Vali Loss: nan Test Loss: 3.3203554
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.3122973442077637
Epoch: 26, Steps: 4 | Train Loss: 0.6237325 Vali Loss: nan Test Loss: 3.3128839
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.2895562648773193
Epoch: 27, Steps: 4 | Train Loss: 0.6341395 Vali Loss: nan Test Loss: 3.3026593
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.365452289581299
Epoch: 28, Steps: 4 | Train Loss: 0.6343915 Vali Loss: nan Test Loss: 3.2947466
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.387446403503418
Epoch: 29, Steps: 4 | Train Loss: 0.6304487 Vali Loss: nan Test Loss: 3.2872801
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.322988748550415
Epoch: 30, Steps: 4 | Train Loss: 0.6317979 Vali Loss: nan Test Loss: 3.2798996
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.2675061225891113
Epoch: 31, Steps: 4 | Train Loss: 0.6106489 Vali Loss: nan Test Loss: 3.2738252
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.4000368118286133
Epoch: 32, Steps: 4 | Train Loss: 0.6141306 Vali Loss: nan Test Loss: 3.2676613
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.292681932449341
Epoch: 33, Steps: 4 | Train Loss: 0.6178946 Vali Loss: nan Test Loss: 3.2607892
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.293748617172241
Epoch: 34, Steps: 4 | Train Loss: 0.6024581 Vali Loss: nan Test Loss: 3.2553885
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.3528940677642822
Epoch: 35, Steps: 4 | Train Loss: 0.6144256 Vali Loss: nan Test Loss: 3.2498434
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.439819812774658
Epoch: 36, Steps: 4 | Train Loss: 0.6156139 Vali Loss: nan Test Loss: 3.2459779
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.109020471572876
Epoch: 37, Steps: 4 | Train Loss: 0.6098382 Vali Loss: nan Test Loss: 3.2425845
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.3879237174987793
Epoch: 38, Steps: 4 | Train Loss: 0.6083394 Vali Loss: nan Test Loss: 3.2400761
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.394688606262207
Epoch: 39, Steps: 4 | Train Loss: 0.5963282 Vali Loss: nan Test Loss: 3.2373948
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.3146536350250244
Epoch: 40, Steps: 4 | Train Loss: 0.6028546 Vali Loss: nan Test Loss: 3.2347283
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.4106297492980957
Epoch: 41, Steps: 4 | Train Loss: 0.5922399 Vali Loss: nan Test Loss: 3.2333543
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.3355226516723633
Epoch: 42, Steps: 4 | Train Loss: 0.6085935 Vali Loss: nan Test Loss: 3.2327509
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 2.3127896785736084
Epoch: 43, Steps: 4 | Train Loss: 0.6048380 Vali Loss: nan Test Loss: 3.2300692
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 2.3826744556427
Epoch: 44, Steps: 4 | Train Loss: 0.5983711 Vali Loss: nan Test Loss: 3.2285833
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 2.4342100620269775
Epoch: 45, Steps: 4 | Train Loss: 0.5930929 Vali Loss: nan Test Loss: 3.2257679
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 2.362213134765625
Epoch: 46, Steps: 4 | Train Loss: 0.6036320 Vali Loss: nan Test Loss: 3.2249331
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.3706560134887695
Epoch: 47, Steps: 4 | Train Loss: 0.6126505 Vali Loss: nan Test Loss: 3.2235641
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 2.2538082599639893
Epoch: 48, Steps: 4 | Train Loss: 0.5951947 Vali Loss: nan Test Loss: 3.2224860
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 2.31390118598938
Epoch: 49, Steps: 4 | Train Loss: 0.6024462 Vali Loss: nan Test Loss: 3.2218549
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 2.4288806915283203
Epoch: 50, Steps: 4 | Train Loss: 0.6088874 Vali Loss: nan Test Loss: 3.2213161
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.1548118591308594
Epoch: 51, Steps: 4 | Train Loss: 0.5933958 Vali Loss: nan Test Loss: 3.2210348
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.2301807403564453
Epoch: 52, Steps: 4 | Train Loss: 0.5974956 Vali Loss: nan Test Loss: 3.2203591
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.289685010910034
Epoch: 53, Steps: 4 | Train Loss: 0.6082524 Vali Loss: nan Test Loss: 3.2200487
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 2.2546486854553223
Epoch: 54, Steps: 4 | Train Loss: 0.5959282 Vali Loss: nan Test Loss: 3.2197027
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 2.4020981788635254
Epoch: 55, Steps: 4 | Train Loss: 0.5952200 Vali Loss: nan Test Loss: 3.2194271
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.403439998626709
Epoch: 56, Steps: 4 | Train Loss: 0.5984961 Vali Loss: nan Test Loss: 3.2190859
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 2.27950382232666
Epoch: 57, Steps: 4 | Train Loss: 0.6024070 Vali Loss: nan Test Loss: 3.2182350
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 2.311821222305298
Epoch: 58, Steps: 4 | Train Loss: 0.6149789 Vali Loss: nan Test Loss: 3.2180247
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 2.398235559463501
Epoch: 59, Steps: 4 | Train Loss: 0.6015123 Vali Loss: nan Test Loss: 3.2174246
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 2.3987135887145996
Epoch: 60, Steps: 4 | Train Loss: 0.6068638 Vali Loss: nan Test Loss: 3.2172370
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 2.424034357070923
Epoch: 61, Steps: 4 | Train Loss: 0.6116203 Vali Loss: nan Test Loss: 3.2165046
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 2.417194128036499
Epoch: 62, Steps: 4 | Train Loss: 0.6282052 Vali Loss: nan Test Loss: 3.2163579
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 2.289340019226074
Epoch: 63, Steps: 4 | Train Loss: 0.6066123 Vali Loss: nan Test Loss: 3.2162225
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 2.4352869987487793
Epoch: 64, Steps: 4 | Train Loss: 0.6137878 Vali Loss: nan Test Loss: 3.2159917
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.1137590408325195
Epoch: 65, Steps: 4 | Train Loss: 0.6098748 Vali Loss: nan Test Loss: 3.2158685
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 2.3491809368133545
Epoch: 66, Steps: 4 | Train Loss: 0.6024781 Vali Loss: nan Test Loss: 3.2155240
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.4086673259735107
Epoch: 67, Steps: 4 | Train Loss: 0.6214876 Vali Loss: nan Test Loss: 3.2154129
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 2.045419692993164
Epoch: 68, Steps: 4 | Train Loss: 0.6144280 Vali Loss: nan Test Loss: 3.2153308
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 2.348639726638794
Epoch: 69, Steps: 4 | Train Loss: 0.5942473 Vali Loss: nan Test Loss: 3.2150264
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.235097646713257
Epoch: 70, Steps: 4 | Train Loss: 0.5893039 Vali Loss: nan Test Loss: 3.2149646
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 2.1533572673797607
Epoch: 71, Steps: 4 | Train Loss: 0.5957047 Vali Loss: nan Test Loss: 3.2149806
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.3652403354644775
Epoch: 72, Steps: 4 | Train Loss: 0.5964069 Vali Loss: nan Test Loss: 3.2149234
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 2.3137314319610596
Epoch: 73, Steps: 4 | Train Loss: 0.5965887 Vali Loss: nan Test Loss: 3.2148681
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.3293662071228027
Epoch: 74, Steps: 4 | Train Loss: 0.5818698 Vali Loss: nan Test Loss: 3.2148156
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 2.3862321376800537
Epoch: 75, Steps: 4 | Train Loss: 0.5972035 Vali Loss: nan Test Loss: 3.2145753
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 2.2147390842437744
Epoch: 76, Steps: 4 | Train Loss: 0.5952344 Vali Loss: nan Test Loss: 3.2141171
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 2.408754348754883
Epoch: 77, Steps: 4 | Train Loss: 0.6020703 Vali Loss: nan Test Loss: 3.2140951
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 2.3429510593414307
Epoch: 78, Steps: 4 | Train Loss: 0.5817752 Vali Loss: nan Test Loss: 3.2140648
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 2.246025562286377
Epoch: 79, Steps: 4 | Train Loss: 0.6085242 Vali Loss: nan Test Loss: 3.2140408
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.3319246768951416
Epoch: 80, Steps: 4 | Train Loss: 0.6127694 Vali Loss: nan Test Loss: 3.2140172
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 2.449492931365967
Epoch: 81, Steps: 4 | Train Loss: 0.6040398 Vali Loss: nan Test Loss: 3.2139945
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.384739875793457
Epoch: 82, Steps: 4 | Train Loss: 0.6094984 Vali Loss: nan Test Loss: 3.2139702
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 2.3675754070281982
Epoch: 83, Steps: 4 | Train Loss: 0.6121688 Vali Loss: nan Test Loss: 3.2139509
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 2.1036930084228516
Epoch: 84, Steps: 4 | Train Loss: 0.5929248 Vali Loss: nan Test Loss: 3.2139318
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 2.416624069213867
Epoch: 85, Steps: 4 | Train Loss: 0.5965643 Vali Loss: nan Test Loss: 3.2139168
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 2.4257781505584717
Epoch: 86, Steps: 4 | Train Loss: 0.5858013 Vali Loss: nan Test Loss: 3.2139030
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.4065158367156982
Epoch: 87, Steps: 4 | Train Loss: 0.6003143 Vali Loss: nan Test Loss: 3.2138860
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 2.4000768661499023
Epoch: 88, Steps: 4 | Train Loss: 0.5908881 Vali Loss: nan Test Loss: 3.2138791
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.3817005157470703
Epoch: 89, Steps: 4 | Train Loss: 0.6017368 Vali Loss: nan Test Loss: 3.2138655
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 2.354645013809204
Epoch: 90, Steps: 4 | Train Loss: 0.6120888 Vali Loss: nan Test Loss: 3.2138567
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 2.277550458908081
Epoch: 91, Steps: 4 | Train Loss: 0.6013608 Vali Loss: nan Test Loss: 3.2138486
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 2.4313106536865234
Epoch: 92, Steps: 4 | Train Loss: 0.6070400 Vali Loss: nan Test Loss: 3.2138405
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.15572190284729
Epoch: 93, Steps: 4 | Train Loss: 0.6112722 Vali Loss: nan Test Loss: 3.2138329
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 2.2934796810150146
Epoch: 94, Steps: 4 | Train Loss: 0.6166929 Vali Loss: nan Test Loss: 3.2138250
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.5324325561523438
Epoch: 95, Steps: 4 | Train Loss: 0.5732828 Vali Loss: nan Test Loss: 3.2138169
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 2.313478946685791
Epoch: 96, Steps: 4 | Train Loss: 0.5965826 Vali Loss: nan Test Loss: 3.2138126
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.349623918533325
Epoch: 97, Steps: 4 | Train Loss: 0.5944298 Vali Loss: nan Test Loss: 3.2138050
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 2.240719795227051
Epoch: 98, Steps: 4 | Train Loss: 0.5991086 Vali Loss: nan Test Loss: 3.2138014
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 2.29496431350708
Epoch: 99, Steps: 4 | Train Loss: 0.6042891 Vali Loss: nan Test Loss: 3.2138007
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 2.3514134883880615
Epoch: 100, Steps: 4 | Train Loss: 0.5942283 Vali Loss: nan Test Loss: 3.2137966
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : ili_36_60_Autoformer_custom_ftM_sl36_ll18_pl60_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 134
mse:3.213796377182007, mae:1.2130151987075806, rse:0.8566316366195679
