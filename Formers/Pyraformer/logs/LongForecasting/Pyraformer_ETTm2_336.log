[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=64, d_inner_hid=512, d_k=64, d_model=256, d_v=64, data='ETTm2', data_path='ETTm2.csv', dec_in=7, decoder='FC', dropout=0.2, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=5, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=336, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 5128320
train 34129
test 11185
[ Epoch 1 ]
  - (Training) MSE:  0.36896elapse: 0.401 min
(11185, 336, 7)
test shape:(11185, 336, 7)
Epoch 0, mse:1.3981612920761108, mae:0.921212375164032, rmse:1.1824387311935425, mape:8.983012199401855, mspe:14445.1591796875
[ Epoch 2 ]
  - (Training) MSE:  0.26513elapse: 0.403 min
(11185, 336, 7)
test shape:(11185, 336, 7)
Epoch 1, mse:1.3969465494155884, mae:0.9275571703910828, rmse:1.1819249391555786, mape:9.340127944946289, mspe:15360.63671875
[ Epoch 3 ]
  - (Training) MSE:  0.25730elapse: 0.392 min
(11185, 336, 7)
test shape:(11185, 336, 7)
Epoch 2, mse:1.3918142318725586, mae:0.9288125038146973, rmse:1.1797517538070679, mape:9.275781631469727, mspe:14955.125
[ Epoch 4 ]
  - (Training) MSE:  0.25627elapse: 0.404 min
(11185, 336, 7)
test shape:(11185, 336, 7)
Epoch 3, mse:1.3831911087036133, mae:0.9252501130104065, rmse:1.1760914325714111, mape:9.239538192749023, mspe:14822.6943359375
[ Epoch 5 ]
  - (Training) MSE:  0.25639elapse: 0.406 min
(11185, 336, 7)
test shape:(11185, 336, 7)
Epoch 4, mse:1.39604914188385, mae:0.9295240044593811, rmse:1.1815452575683594, mape:9.335033416748047, mspe:15162.9228515625
Iteration best metrics: [1.3831911087036133, 0.9252501130104065, 1.1760914325714111, 9.239538192749023, 14822.6943359375]
Average Metrics: [1.38319111e+00 9.25250113e-01 1.17609143e+00 9.23953819e+00
 1.48226943e+04]
