Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='Autoformer', model_id='ili_36_48', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=48, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ili_36_48_Autoformer_custom_ftM_sl36_ll18_pl48_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 593
val 50
test 146
Epoch: 1 cost time: 2.310140609741211
Epoch: 1, Steps: 4 | Train Loss: 1.4053122 Vali Loss: nan Test Loss: 4.5169082
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.235927104949951
Epoch: 2, Steps: 4 | Train Loss: 1.3423190 Vali Loss: nan Test Loss: 4.1691089
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.2958195209503174
Epoch: 3, Steps: 4 | Train Loss: 1.0582101 Vali Loss: nan Test Loss: 3.9833243
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.310584783554077
Epoch: 4, Steps: 4 | Train Loss: 1.0506406 Vali Loss: nan Test Loss: 3.7497878
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.243330240249634
Epoch: 5, Steps: 4 | Train Loss: 0.8985834 Vali Loss: nan Test Loss: 3.5433321
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.369361400604248
Epoch: 6, Steps: 4 | Train Loss: 0.8586030 Vali Loss: nan Test Loss: 3.4088960
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.3473575115203857
Epoch: 7, Steps: 4 | Train Loss: 0.7968216 Vali Loss: nan Test Loss: 3.3185620
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.392045259475708
Epoch: 8, Steps: 4 | Train Loss: 0.7409903 Vali Loss: nan Test Loss: 3.2505589
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.4001879692077637
Epoch: 9, Steps: 4 | Train Loss: 0.7152746 Vali Loss: nan Test Loss: 3.1907597
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.3742315769195557
Epoch: 10, Steps: 4 | Train Loss: 0.6931376 Vali Loss: nan Test Loss: 3.1338148
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.414935827255249
Epoch: 11, Steps: 4 | Train Loss: 0.6871145 Vali Loss: nan Test Loss: 3.0838339
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.336745023727417
Epoch: 12, Steps: 4 | Train Loss: 0.6632773 Vali Loss: nan Test Loss: 3.0341070
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.3674826622009277
Epoch: 13, Steps: 4 | Train Loss: 0.6210855 Vali Loss: nan Test Loss: 2.9815297
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.195794105529785
Epoch: 14, Steps: 4 | Train Loss: 0.6476852 Vali Loss: nan Test Loss: 2.9324217
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.5897984504699707
Epoch: 15, Steps: 4 | Train Loss: 0.6162495 Vali Loss: nan Test Loss: 2.8874922
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.301194429397583
Epoch: 16, Steps: 4 | Train Loss: 0.6371410 Vali Loss: nan Test Loss: 2.8461726
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.318571090698242
Epoch: 17, Steps: 4 | Train Loss: 0.6182652 Vali Loss: nan Test Loss: 2.8124394
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.364063024520874
Epoch: 18, Steps: 4 | Train Loss: 0.6146301 Vali Loss: nan Test Loss: 2.7863004
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.3895201683044434
Epoch: 19, Steps: 4 | Train Loss: 0.5878050 Vali Loss: nan Test Loss: 2.7664533
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.2714250087738037
Epoch: 20, Steps: 4 | Train Loss: 0.6142506 Vali Loss: nan Test Loss: 2.7537141
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.3693597316741943
Epoch: 21, Steps: 4 | Train Loss: 0.5868176 Vali Loss: nan Test Loss: 2.7462690
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.108325242996216
Epoch: 22, Steps: 4 | Train Loss: 0.5857590 Vali Loss: nan Test Loss: 2.7395191
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.252417802810669
Epoch: 23, Steps: 4 | Train Loss: 0.6053184 Vali Loss: nan Test Loss: 2.7354412
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.1840200424194336
Epoch: 24, Steps: 4 | Train Loss: 0.5860475 Vali Loss: nan Test Loss: 2.7325826
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.345257043838501
Epoch: 25, Steps: 4 | Train Loss: 0.6000181 Vali Loss: nan Test Loss: 2.7302217
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.3012068271636963
Epoch: 26, Steps: 4 | Train Loss: 0.5913865 Vali Loss: nan Test Loss: 2.7293589
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.283541679382324
Epoch: 27, Steps: 4 | Train Loss: 0.5872923 Vali Loss: nan Test Loss: 2.7261877
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.1935532093048096
Epoch: 28, Steps: 4 | Train Loss: 0.5852565 Vali Loss: nan Test Loss: 2.7214882
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.410098075866699
Epoch: 29, Steps: 4 | Train Loss: 0.5750953 Vali Loss: nan Test Loss: 2.7170537
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.356078863143921
Epoch: 30, Steps: 4 | Train Loss: 0.5773319 Vali Loss: nan Test Loss: 2.7140317
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.312796115875244
Epoch: 31, Steps: 4 | Train Loss: 0.5726153 Vali Loss: nan Test Loss: 2.7122402
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.236896514892578
Epoch: 32, Steps: 4 | Train Loss: 0.5926892 Vali Loss: nan Test Loss: 2.7102559
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.256887912750244
Epoch: 33, Steps: 4 | Train Loss: 0.5933670 Vali Loss: nan Test Loss: 2.7088022
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.312152624130249
Epoch: 34, Steps: 4 | Train Loss: 0.5801567 Vali Loss: nan Test Loss: 2.7063341
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.3472907543182373
Epoch: 35, Steps: 4 | Train Loss: 0.5677538 Vali Loss: nan Test Loss: 2.7060199
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.314288377761841
Epoch: 36, Steps: 4 | Train Loss: 0.5758618 Vali Loss: nan Test Loss: 2.7045841
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.390188455581665
Epoch: 37, Steps: 4 | Train Loss: 0.5767402 Vali Loss: nan Test Loss: 2.7032931
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.234175682067871
Epoch: 38, Steps: 4 | Train Loss: 0.5921260 Vali Loss: nan Test Loss: 2.7027287
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.156686782836914
Epoch: 39, Steps: 4 | Train Loss: 0.5960338 Vali Loss: nan Test Loss: 2.7018216
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.397116184234619
Epoch: 40, Steps: 4 | Train Loss: 0.6028045 Vali Loss: nan Test Loss: 2.7022586
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.379720449447632
Epoch: 41, Steps: 4 | Train Loss: 0.5691503 Vali Loss: nan Test Loss: 2.7025125
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.304959535598755
Epoch: 42, Steps: 4 | Train Loss: 0.5812875 Vali Loss: nan Test Loss: 2.7025568
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 2.321345806121826
Epoch: 43, Steps: 4 | Train Loss: 0.5894317 Vali Loss: nan Test Loss: 2.7031918
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 2.302875518798828
Epoch: 44, Steps: 4 | Train Loss: 0.6047170 Vali Loss: nan Test Loss: 2.7033575
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 2.3425827026367188
Epoch: 45, Steps: 4 | Train Loss: 0.5864854 Vali Loss: nan Test Loss: 2.7026734
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 2.3808531761169434
Epoch: 46, Steps: 4 | Train Loss: 0.5784118 Vali Loss: nan Test Loss: 2.7027228
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.335911750793457
Epoch: 47, Steps: 4 | Train Loss: 0.5977611 Vali Loss: nan Test Loss: 2.7021229
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 2.3590190410614014
Epoch: 48, Steps: 4 | Train Loss: 0.5623195 Vali Loss: nan Test Loss: 2.7018938
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 2.3578155040740967
Epoch: 49, Steps: 4 | Train Loss: 0.5753414 Vali Loss: nan Test Loss: 2.7015331
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 2.3428726196289062
Epoch: 50, Steps: 4 | Train Loss: 0.5672257 Vali Loss: nan Test Loss: 2.7013543
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.3581936359405518
Epoch: 51, Steps: 4 | Train Loss: 0.5581135 Vali Loss: nan Test Loss: 2.7012966
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.310281276702881
Epoch: 52, Steps: 4 | Train Loss: 0.5705558 Vali Loss: nan Test Loss: 2.7012835
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.2926788330078125
Epoch: 53, Steps: 4 | Train Loss: 0.5710966 Vali Loss: nan Test Loss: 2.7013218
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 2.199918508529663
Epoch: 54, Steps: 4 | Train Loss: 0.5824668 Vali Loss: nan Test Loss: 2.7009139
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 2.4195401668548584
Epoch: 55, Steps: 4 | Train Loss: 0.5696378 Vali Loss: nan Test Loss: 2.7006762
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.353179931640625
Epoch: 56, Steps: 4 | Train Loss: 0.5442886 Vali Loss: nan Test Loss: 2.7006235
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 2.389998197555542
Epoch: 57, Steps: 4 | Train Loss: 0.5547406 Vali Loss: nan Test Loss: 2.7006145
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 2.222825288772583
Epoch: 58, Steps: 4 | Train Loss: 0.5824619 Vali Loss: nan Test Loss: 2.7005656
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 2.4770491123199463
Epoch: 59, Steps: 4 | Train Loss: 0.5713360 Vali Loss: nan Test Loss: 2.7005181
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 2.3578836917877197
Epoch: 60, Steps: 4 | Train Loss: 0.5570413 Vali Loss: nan Test Loss: 2.7004435
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 2.145878791809082
Epoch: 61, Steps: 4 | Train Loss: 0.5629734 Vali Loss: nan Test Loss: 2.7003384
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 2.4205567836761475
Epoch: 62, Steps: 4 | Train Loss: 0.5595797 Vali Loss: nan Test Loss: 2.7002537
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 2.1592047214508057
Epoch: 63, Steps: 4 | Train Loss: 0.5864754 Vali Loss: nan Test Loss: 2.7005260
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 2.2463228702545166
Epoch: 64, Steps: 4 | Train Loss: 0.5671716 Vali Loss: nan Test Loss: 2.7004101
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.13110089302063
Epoch: 65, Steps: 4 | Train Loss: 0.5816689 Vali Loss: nan Test Loss: 2.7004838
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 2.2870800495147705
Epoch: 66, Steps: 4 | Train Loss: 0.5951334 Vali Loss: nan Test Loss: 2.7004151
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.3624579906463623
Epoch: 67, Steps: 4 | Train Loss: 0.5702486 Vali Loss: nan Test Loss: 2.7003503
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 2.3783740997314453
Epoch: 68, Steps: 4 | Train Loss: 0.5832817 Vali Loss: nan Test Loss: 2.7006905
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 2.284285068511963
Epoch: 69, Steps: 4 | Train Loss: 0.5654322 Vali Loss: nan Test Loss: 2.7008195
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.3683812618255615
Epoch: 70, Steps: 4 | Train Loss: 0.5868671 Vali Loss: nan Test Loss: 2.7007611
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 2.3334691524505615
Epoch: 71, Steps: 4 | Train Loss: 0.5693481 Vali Loss: nan Test Loss: 2.7007072
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.3067355155944824
Epoch: 72, Steps: 4 | Train Loss: 0.5500989 Vali Loss: nan Test Loss: 2.7006443
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 2.2587099075317383
Epoch: 73, Steps: 4 | Train Loss: 0.5533146 Vali Loss: nan Test Loss: 2.7006428
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.3321707248687744
Epoch: 74, Steps: 4 | Train Loss: 0.5511925 Vali Loss: nan Test Loss: 2.7006953
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 2.2900962829589844
Epoch: 75, Steps: 4 | Train Loss: 0.5821926 Vali Loss: nan Test Loss: 2.7006693
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 2.300854206085205
Epoch: 76, Steps: 4 | Train Loss: 0.5815801 Vali Loss: nan Test Loss: 2.7006490
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 2.44027042388916
Epoch: 77, Steps: 4 | Train Loss: 0.5648653 Vali Loss: nan Test Loss: 2.7006299
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 2.269667863845825
Epoch: 78, Steps: 4 | Train Loss: 0.5521416 Vali Loss: nan Test Loss: 2.7008920
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 2.1755802631378174
Epoch: 79, Steps: 4 | Train Loss: 0.5738577 Vali Loss: nan Test Loss: 2.7008770
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.205341339111328
Epoch: 80, Steps: 4 | Train Loss: 0.5734636 Vali Loss: nan Test Loss: 2.7008564
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 2.3623340129852295
Epoch: 81, Steps: 4 | Train Loss: 0.5684895 Vali Loss: nan Test Loss: 2.7008660
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.413360834121704
Epoch: 82, Steps: 4 | Train Loss: 0.5816108 Vali Loss: nan Test Loss: 2.7008541
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 2.2109808921813965
Epoch: 83, Steps: 4 | Train Loss: 0.5835301 Vali Loss: nan Test Loss: 2.7008457
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 2.364227056503296
Epoch: 84, Steps: 4 | Train Loss: 0.5631702 Vali Loss: nan Test Loss: 2.7008333
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 2.342193365097046
Epoch: 85, Steps: 4 | Train Loss: 0.5852439 Vali Loss: nan Test Loss: 2.7008190
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 2.3902759552001953
Epoch: 86, Steps: 4 | Train Loss: 0.5801367 Vali Loss: nan Test Loss: 2.7008090
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.3923351764678955
Epoch: 87, Steps: 4 | Train Loss: 0.5817975 Vali Loss: nan Test Loss: 2.7008007
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 2.138448715209961
Epoch: 88, Steps: 4 | Train Loss: 0.5539255 Vali Loss: nan Test Loss: 2.7007926
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.370516777038574
Epoch: 89, Steps: 4 | Train Loss: 0.5764120 Vali Loss: nan Test Loss: 2.7007883
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 2.2333943843841553
Epoch: 90, Steps: 4 | Train Loss: 0.5693716 Vali Loss: nan Test Loss: 2.7007806
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 2.374361753463745
Epoch: 91, Steps: 4 | Train Loss: 0.5895302 Vali Loss: nan Test Loss: 2.7007747
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 2.258343458175659
Epoch: 92, Steps: 4 | Train Loss: 0.5847951 Vali Loss: nan Test Loss: 2.7007692
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.127302885055542
Epoch: 93, Steps: 4 | Train Loss: 0.5605194 Vali Loss: nan Test Loss: 2.7007651
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 2.25248646736145
Epoch: 94, Steps: 4 | Train Loss: 0.5731658 Vali Loss: nan Test Loss: 2.7007599
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.362391948699951
Epoch: 95, Steps: 4 | Train Loss: 0.5778069 Vali Loss: nan Test Loss: 2.7007565
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 2.3597524166107178
Epoch: 96, Steps: 4 | Train Loss: 0.5593219 Vali Loss: nan Test Loss: 2.7007527
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.329728364944458
Epoch: 97, Steps: 4 | Train Loss: 0.5795806 Vali Loss: nan Test Loss: 2.7007487
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 2.3897383213043213
Epoch: 98, Steps: 4 | Train Loss: 0.5761902 Vali Loss: nan Test Loss: 2.7007482
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 2.2331666946411133
Epoch: 99, Steps: 4 | Train Loss: 0.5642073 Vali Loss: nan Test Loss: 2.7007427
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 2.3819024562835693
Epoch: 100, Steps: 4 | Train Loss: 0.5722147 Vali Loss: nan Test Loss: 2.7007427
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : ili_36_48_Autoformer_custom_ftM_sl36_ll18_pl48_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 146
mse:2.700742721557617, mae:1.0899180173873901, rse:0.78936368227005
