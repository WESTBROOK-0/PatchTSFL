[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=16, covariate_size=4, d_bottleneck=64, d_inner_hid=512, d_k=64, d_model=256, d_v=64, data='ETTm1', data_path='ETTm1.csv', dec_in=7, decoder='FC', dropout=0.2, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=720, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 7880832
train 33745
test 10801
[ Epoch 1 ]
  - (Training) MSE:  0.42651elapse: 0.724 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 0, mse:1.0477869510650635, mae:0.7870919704437256, rmse:1.0236146450042725, mape:3.944992780685425, mspe:1085.0831298828125
[ Epoch 2 ]
  - (Training) MSE:  0.33169elapse: 0.721 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 1, mse:1.1259599924087524, mae:0.8052955269813538, rmse:1.061112642288208, mape:4.093866348266602, mspe:1339.4676513671875
[ Epoch 3 ]
  - (Training) MSE:  0.32538elapse: 0.735 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 2, mse:1.0998985767364502, mae:0.7922086119651794, rmse:1.0487605333328247, mape:4.009576797485352, mspe:1270.021484375
[ Epoch 4 ]
  - (Training) MSE:  0.32472elapse: 0.744 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 3, mse:1.1267311573028564, mae:0.8003334403038025, rmse:1.0614759922027588, mape:4.0805745124816895, mspe:1342.1031494140625
[ Epoch 5 ]
  - (Training) MSE:  0.32431elapse: 0.731 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 4, mse:1.119493842124939, mae:0.7976933121681213, rmse:1.0580613613128662, mape:4.039968490600586, mspe:1331.8021240234375
Iteration best metrics: [1.0477869510650635, 0.7870919704437256, 1.0236146450042725, 3.944992780685425, 1085.0831298828125]
Average Metrics: [1.04778695e+00 7.87091970e-01 1.02361465e+00 3.94499278e+00
 1.08508313e+03]
