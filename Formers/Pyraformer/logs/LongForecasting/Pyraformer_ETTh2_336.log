[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=128, d_inner_hid=512, d_k=128, d_model=512, d_v=128, data='ETTh2', data_path='ETTh2.csv', dec_in=7, decoder='FC', dropout=0.05, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=336, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 13564160
train 8209
test 2545
[ Epoch 1 ]
  - (Training) MSE:  0.49751elapse: 0.103 min
(2545, 336, 7)
test shape:(2545, 336, 7)
Epoch 0, mse:4.435366630554199, mae:1.7632925510406494, rmse:2.1060309410095215, mape:13.932454109191895, mspe:10836.5810546875
[ Epoch 2 ]
  - (Training) MSE:  0.33558elapse: 0.103 min
(2545, 336, 7)
test shape:(2545, 336, 7)
Epoch 1, mse:4.5531907081604, mae:1.7846193313598633, rmse:2.1338207721710205, mape:15.154637336730957, mspe:13033.2685546875
[ Epoch 3 ]
  - (Training) MSE:  0.32310elapse: 0.105 min
(2545, 336, 7)
test shape:(2545, 336, 7)
Epoch 2, mse:4.690508842468262, mae:1.8148249387741089, rmse:2.1657583713531494, mape:15.324078559875488, mspe:13238.3427734375
[ Epoch 4 ]
  - (Training) MSE:  0.32041elapse: 0.103 min
(2545, 336, 7)
test shape:(2545, 336, 7)
Epoch 3, mse:4.704606056213379, mae:1.8199176788330078, rmse:2.1690104007720947, mape:15.215645790100098, mspe:13068.82421875
[ Epoch 5 ]
  - (Training) MSE:  0.32141elapse: 0.103 min
(2545, 336, 7)
test shape:(2545, 336, 7)
Epoch 4, mse:4.6761155128479, mae:1.8119219541549683, rmse:2.1624326705932617, mape:15.127840042114258, mspe:12888.986328125
Iteration best metrics: [4.435366630554199, 1.7632925510406494, 2.1060309410095215, 13.932454109191895, 10836.5810546875]
Average Metrics: [4.43536663e+00 1.76329255e+00 2.10603094e+00 1.39324541e+01
 1.08365811e+04]
