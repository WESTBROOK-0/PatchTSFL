[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=64, d_inner_hid=512, d_k=64, d_model=256, d_v=64, data='ETTm2', data_path='ETTm2.csv', dec_in=7, decoder='FC', dropout=0.2, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=96, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 3408000
train 34369
test 11425
[ Epoch 1 ]
  - (Training) MSE:  0.34248elapse: 0.461 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 0, mse:0.5121356248855591, mae:0.578029215335846, rmse:0.7156364917755127, mape:4.108405113220215, mspe:1877.40283203125
[ Epoch 2 ]
  - (Training) MSE:  0.22428elapse: 0.478 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 1, mse:0.4634205996990204, mae:0.5412485003471375, rmse:0.6807500123977661, mape:3.689631223678589, mspe:1589.71240234375
[ Epoch 3 ]
  - (Training) MSE:  0.21750elapse: 0.461 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 2, mse:0.45852360129356384, mae:0.5370582938194275, rmse:0.6771436929702759, mape:3.6693921089172363, mspe:1555.55078125
[ Epoch 4 ]
  - (Training) MSE:  0.21675elapse: 0.413 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 3, mse:0.4561370015144348, mae:0.5358965396881104, rmse:0.6753791570663452, mape:3.7406692504882812, mspe:1648.2335205078125
[ Epoch 5 ]
  - (Training) MSE:  0.21701elapse: 0.401 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 4, mse:0.4451722800731659, mae:0.5262898206710815, rmse:0.6672123074531555, mape:3.597825765609741, mspe:1507.6895751953125
Iteration best metrics: [0.4451722800731659, 0.5262898206710815, 0.6672123074531555, 3.597825765609741, 1507.6895751953125]
Average Metrics: [4.45172280e-01 5.26289821e-01 6.67212307e-01 3.59782577e+00
 1.50768958e+03]
