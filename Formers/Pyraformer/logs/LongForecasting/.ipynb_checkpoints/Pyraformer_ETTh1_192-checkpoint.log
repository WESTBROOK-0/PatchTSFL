[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=128, d_inner_hid=512, d_k=128, d_model=512, d_v=128, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decoder='FC', dropout=0.05, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=192, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 11499776
train 8353
test 2689
[ Epoch 1 ]
  - (Training) MSE:  0.53268elapse: 0.104 min
(2689, 192, 7)
test shape:(2689, 192, 7)
Epoch 0, mse:0.8333531618118286, mae:0.699441134929657, rmse:0.9128817915916443, mape:11.313966751098633, mspe:43501.86328125
[ Epoch 2 ]
  - (Training) MSE:  0.39145elapse: 0.096 min
(2689, 192, 7)
test shape:(2689, 192, 7)
Epoch 1, mse:0.8437685966491699, mae:0.7166962623596191, rmse:0.9185687899589539, mape:11.546643257141113, mspe:45421.99609375
[ Epoch 3 ]
  - (Training) MSE:  0.38171elapse: 0.092 min
(2689, 192, 7)
test shape:(2689, 192, 7)
Epoch 2, mse:0.8495000004768372, mae:0.7237250208854675, rmse:0.9216832518577576, mape:12.460805892944336, mspe:53134.41015625
[ Epoch 4 ]
  - (Training) MSE:  0.38073elapse: 0.092 min
(2689, 192, 7)
test shape:(2689, 192, 7)
Epoch 3, mse:0.8525487184524536, mae:0.7242628931999207, rmse:0.9233356714248657, mape:11.819212913513184, mspe:47369.875
[ Epoch 5 ]
  - (Training) MSE:  0.38052elapse: 0.093 min
(2689, 192, 7)
test shape:(2689, 192, 7)
Epoch 4, mse:0.8486827611923218, mae:0.7214431166648865, rmse:0.9212397933006287, mape:11.899084091186523, mspe:48278.0390625
Iteration best metrics: [0.8333531618118286, 0.699441134929657, 0.9128817915916443, 11.313966751098633, 43501.86328125]
Average Metrics: [8.33353162e-01 6.99441135e-01 9.12881792e-01 1.13139668e+01
 4.35018633e+04]
