[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=16, covariate_size=4, d_bottleneck=64, d_inner_hid=512, d_k=64, d_model=256, d_v=64, data='ETTm1', data_path='ETTm1.csv', dec_in=7, decoder='FC', dropout=0.2, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=192, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 4096128
train 34273
test 11329
[ Epoch 1 ]
  - (Training) MSE:  0.41360elapse: 0.879 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 0, mse:0.5532835125923157, mae:0.5279107689857483, rmse:0.7438303232192993, mape:2.3377647399902344, mspe:291.3380126953125
[ Epoch 2 ]
  - (Training) MSE:  0.31041elapse: 0.862 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 1, mse:0.5881304740905762, mae:0.55643630027771, rmse:0.766896665096283, mape:2.468588352203369, mspe:338.5253601074219
[ Epoch 3 ]
  - (Training) MSE:  0.30342elapse: 0.869 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 2, mse:0.5782922506332397, mae:0.5440813302993774, rmse:0.760455310344696, mape:2.3788199424743652, mspe:305.8335266113281
[ Epoch 4 ]
  - (Training) MSE:  0.30271elapse: 0.853 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 3, mse:0.5788528323173523, mae:0.5446226000785828, rmse:0.7608237862586975, mape:2.420302629470825, mspe:318.01837158203125
[ Epoch 5 ]
  - (Training) MSE:  0.30228elapse: 0.864 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 4, mse:0.5798103213310242, mae:0.5435570478439331, rmse:0.7614527940750122, mape:2.374717950820923, mspe:302.83880615234375
Iteration best metrics: [0.5532835125923157, 0.5279107689857483, 0.7438303232192993, 2.3377647399902344, 291.3380126953125]
Average Metrics: [  0.55328351   0.52791077   0.74383032   2.33776474 291.3380127 ]
