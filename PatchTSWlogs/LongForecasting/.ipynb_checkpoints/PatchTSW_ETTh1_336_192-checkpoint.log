Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=128, d_layers=1, d_model=16, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.3, e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', model='PatchTSW', model_id='336_192', moving_avg=25, n_heads=4, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=192, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
base legendre
>>>>>>>start training : 336_192_PatchTSW_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
Epoch: 1 cost time: 32.19201064109802
Epoch: 1, Steps: 63 | Train Loss: 0.7283165 Vali Loss: 1.5097425 Test Loss: 0.7317778
Validation loss decreased (inf --> 1.509742).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 32.08586263656616
Epoch: 2, Steps: 63 | Train Loss: 0.5285675 Vali Loss: 0.9751533 Test Loss: 0.4582721
Validation loss decreased (1.509742 --> 0.975153).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 32.24152708053589
Epoch: 3, Steps: 63 | Train Loss: 0.4648464 Vali Loss: 0.9554697 Test Loss: 0.4413250
Validation loss decreased (0.975153 --> 0.955470).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 32.28234052658081
Epoch: 4, Steps: 63 | Train Loss: 0.4501627 Vali Loss: 0.9601676 Test Loss: 0.4365949
EarlyStopping counter: 1 out of 100
Updating learning rate to 9e-05
Epoch: 5 cost time: 32.25772953033447
Epoch: 5, Steps: 63 | Train Loss: 0.4420280 Vali Loss: 0.9457701 Test Loss: 0.4335375
Validation loss decreased (0.955470 --> 0.945770).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 32.32524299621582
Epoch: 6, Steps: 63 | Train Loss: 0.4372301 Vali Loss: 0.9513482 Test Loss: 0.4325922
EarlyStopping counter: 1 out of 100
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 32.400829792022705
Epoch: 7, Steps: 63 | Train Loss: 0.4334409 Vali Loss: 0.9452978 Test Loss: 0.4300429
Validation loss decreased (0.945770 --> 0.945298).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 32.308711767196655
Epoch: 8, Steps: 63 | Train Loss: 0.4300819 Vali Loss: 0.9493460 Test Loss: 0.4270036
EarlyStopping counter: 1 out of 100
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 32.40481400489807
Epoch: 9, Steps: 63 | Train Loss: 0.4272763 Vali Loss: 0.9591371 Test Loss: 0.4261627
EarlyStopping counter: 2 out of 100
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 32.65934777259827
Epoch: 10, Steps: 63 | Train Loss: 0.4246188 Vali Loss: 0.9390077 Test Loss: 0.4243128
Validation loss decreased (0.945298 --> 0.939008).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 32.471421241760254
Epoch: 11, Steps: 63 | Train Loss: 0.4227989 Vali Loss: 0.9402575 Test Loss: 0.4230963
EarlyStopping counter: 1 out of 100
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 32.40220785140991
Epoch: 12, Steps: 63 | Train Loss: 0.4204194 Vali Loss: 0.9473933 Test Loss: 0.4222350
EarlyStopping counter: 2 out of 100
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 32.58840727806091
Epoch: 13, Steps: 63 | Train Loss: 0.4191053 Vali Loss: 0.9472435 Test Loss: 0.4209943
EarlyStopping counter: 3 out of 100
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 32.26483869552612
Epoch: 14, Steps: 63 | Train Loss: 0.4177328 Vali Loss: 0.9399849 Test Loss: 0.4213670
EarlyStopping counter: 4 out of 100
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 32.384214878082275
Epoch: 15, Steps: 63 | Train Loss: 0.4170754 Vali Loss: 0.9472334 Test Loss: 0.4211761
EarlyStopping counter: 5 out of 100
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 32.3712203502655
Epoch: 16, Steps: 63 | Train Loss: 0.4156268 Vali Loss: 0.9454452 Test Loss: 0.4205308
EarlyStopping counter: 6 out of 100
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 32.48240327835083
Epoch: 17, Steps: 63 | Train Loss: 0.4149522 Vali Loss: 0.9432038 Test Loss: 0.4189751
EarlyStopping counter: 7 out of 100
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 32.23036789894104
Epoch: 18, Steps: 63 | Train Loss: 0.4140071 Vali Loss: 0.9395143 Test Loss: 0.4197408
EarlyStopping counter: 8 out of 100
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 32.18761610984802
Epoch: 19, Steps: 63 | Train Loss: 0.4131388 Vali Loss: 0.9426299 Test Loss: 0.4194059
EarlyStopping counter: 9 out of 100
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 32.60682702064514
Epoch: 20, Steps: 63 | Train Loss: 0.4122017 Vali Loss: 0.9524982 Test Loss: 0.4187022
EarlyStopping counter: 10 out of 100
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 32.30813694000244
Epoch: 21, Steps: 63 | Train Loss: 0.4116961 Vali Loss: 0.9495057 Test Loss: 0.4192844
EarlyStopping counter: 11 out of 100
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 32.35031199455261
