[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=128, d_inner_hid=512, d_k=128, d_model=512, d_v=128, data='ETTh2', data_path='ETTh2.csv', dec_in=7, decoder='FC', dropout=0.05, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=96, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 10123520
train 8449
test 2785
[ Epoch 1 ]
  - (Training) MSE:  0.42571elapse: 0.109 min
(2785, 96, 7)
test shape:(2785, 96, 7)
Epoch 0, mse:1.6077892780303955, mae:1.0063010454177856, rmse:1.2679862976074219, mape:7.376071453094482, mspe:3338.472900390625
[ Epoch 2 ]
  - (Training) MSE:  0.28974elapse: 0.115 min
(2785, 96, 7)
test shape:(2785, 96, 7)
Epoch 1, mse:1.7287794351577759, mae:1.0474778413772583, rmse:1.3148305416107178, mape:8.438401222229004, mspe:4314.1064453125
[ Epoch 3 ]
  - (Training) MSE:  0.27920elapse: 0.118 min
(2785, 96, 7)
test shape:(2785, 96, 7)
Epoch 2, mse:1.6657896041870117, mae:1.0289045572280884, rmse:1.2906547784805298, mape:8.326581001281738, mspe:4337.1015625
[ Epoch 4 ]
  - (Training) MSE:  0.27735elapse: 0.119 min
(2785, 96, 7)
test shape:(2785, 96, 7)
Epoch 3, mse:1.6530375480651855, mae:1.0256420373916626, rmse:1.2857050895690918, mape:8.358434677124023, mspe:4386.09765625
[ Epoch 5 ]
  - (Training) MSE:  0.27789elapse: 0.106 min
(2785, 96, 7)
test shape:(2785, 96, 7)
Epoch 4, mse:1.592575192451477, mae:1.0054789781570435, rmse:1.2619727849960327, mape:8.068127632141113, mspe:4278.32421875
Iteration best metrics: [1.592575192451477, 1.0054789781570435, 1.2619727849960327, 8.068127632141113, 4278.32421875]
Average Metrics: [1.59257519e+00 1.00547898e+00 1.26197278e+00 8.06812763e+00
 4.27832422e+03]
