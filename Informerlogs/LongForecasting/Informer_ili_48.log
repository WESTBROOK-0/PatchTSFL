Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='Informer', model_id='ili_36_48', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=48, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ili_36_48_Informer_custom_ftM_sl36_ll18_pl48_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 593
val 50
test 146
Epoch: 1 cost time: 2.1286723613739014
Epoch: 1, Steps: 4 | Train Loss: 1.3568435 Vali Loss: nan Test Loss: 7.6719031
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.413816452026367
Epoch: 2, Steps: 4 | Train Loss: 1.0179197 Vali Loss: nan Test Loss: 5.1160297
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.0545852184295654
Epoch: 3, Steps: 4 | Train Loss: 0.8596905 Vali Loss: nan Test Loss: 4.5830727
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.4248857498168945
Epoch: 4, Steps: 4 | Train Loss: 0.7740199 Vali Loss: nan Test Loss: 4.9172235
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.2482128143310547
Epoch: 5, Steps: 4 | Train Loss: 0.6512348 Vali Loss: nan Test Loss: 5.1062460
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.335675001144409
Epoch: 6, Steps: 4 | Train Loss: 0.6297584 Vali Loss: nan Test Loss: 4.6982355
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.240055561065674
Epoch: 7, Steps: 4 | Train Loss: 0.5801203 Vali Loss: nan Test Loss: 4.6346078
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.2652993202209473
Epoch: 8, Steps: 4 | Train Loss: 0.5325588 Vali Loss: nan Test Loss: 4.9236593
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.2793092727661133
Epoch: 9, Steps: 4 | Train Loss: 0.5256448 Vali Loss: nan Test Loss: 5.0359321
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.651167869567871
Epoch: 10, Steps: 4 | Train Loss: 0.4904431 Vali Loss: nan Test Loss: 5.0053844
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.229541778564453
Epoch: 11, Steps: 4 | Train Loss: 0.4637049 Vali Loss: nan Test Loss: 5.1737051
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.220662832260132
Epoch: 12, Steps: 4 | Train Loss: 0.4331322 Vali Loss: nan Test Loss: 5.4048100
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.163945436477661
Epoch: 13, Steps: 4 | Train Loss: 0.4412609 Vali Loss: nan Test Loss: 5.3685279
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.133247137069702
Epoch: 14, Steps: 4 | Train Loss: 0.4332484 Vali Loss: nan Test Loss: 5.2129846
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.077284574508667
Epoch: 15, Steps: 4 | Train Loss: 0.4096735 Vali Loss: nan Test Loss: 5.2801719
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.346724510192871
Epoch: 16, Steps: 4 | Train Loss: 0.4033533 Vali Loss: nan Test Loss: 5.3661799
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.154264211654663
Epoch: 17, Steps: 4 | Train Loss: 0.3903392 Vali Loss: nan Test Loss: 5.3307352
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.163341760635376
Epoch: 18, Steps: 4 | Train Loss: 0.3857459 Vali Loss: nan Test Loss: 5.2708521
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.289973735809326
Epoch: 19, Steps: 4 | Train Loss: 0.3876857 Vali Loss: nan Test Loss: 5.2476935
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.267472743988037
Epoch: 20, Steps: 4 | Train Loss: 0.3816252 Vali Loss: nan Test Loss: 5.2561173
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.1662790775299072
Epoch: 21, Steps: 4 | Train Loss: 0.3638230 Vali Loss: nan Test Loss: 5.2879148
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.076897382736206
Epoch: 22, Steps: 4 | Train Loss: 0.3591124 Vali Loss: nan Test Loss: 5.2936563
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.0972461700439453
Epoch: 23, Steps: 4 | Train Loss: 0.3562126 Vali Loss: nan Test Loss: 5.3019247
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.124572515487671
Epoch: 24, Steps: 4 | Train Loss: 0.3651265 Vali Loss: nan Test Loss: 5.2992005
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.2936511039733887
Epoch: 25, Steps: 4 | Train Loss: 0.3557504 Vali Loss: nan Test Loss: 5.2910061
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.1699299812316895
Epoch: 26, Steps: 4 | Train Loss: 0.3569007 Vali Loss: nan Test Loss: 5.2740574
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.044016122817993
Epoch: 27, Steps: 4 | Train Loss: 0.3494852 Vali Loss: nan Test Loss: 5.2597642
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.221734046936035
Epoch: 28, Steps: 4 | Train Loss: 0.3516078 Vali Loss: nan Test Loss: 5.2532263
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.2066214084625244
Epoch: 29, Steps: 4 | Train Loss: 0.3400946 Vali Loss: nan Test Loss: 5.2259283
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.208022117614746
Epoch: 30, Steps: 4 | Train Loss: 0.3402724 Vali Loss: nan Test Loss: 5.1904082
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.133403778076172
Epoch: 31, Steps: 4 | Train Loss: 0.3343265 Vali Loss: nan Test Loss: 5.2186728
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.0561130046844482
Epoch: 32, Steps: 4 | Train Loss: 0.3431765 Vali Loss: nan Test Loss: 5.2113433
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.1634299755096436
Epoch: 33, Steps: 4 | Train Loss: 0.3416020 Vali Loss: nan Test Loss: 5.2543521
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.4370763301849365
Epoch: 34, Steps: 4 | Train Loss: 0.3438316 Vali Loss: nan Test Loss: 5.2347393
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.052518844604492
Epoch: 35, Steps: 4 | Train Loss: 0.3348939 Vali Loss: nan Test Loss: 5.2649150
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.2532784938812256
Epoch: 36, Steps: 4 | Train Loss: 0.3445514 Vali Loss: nan Test Loss: 5.2428417
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.2558045387268066
Epoch: 37, Steps: 4 | Train Loss: 0.3346452 Vali Loss: nan Test Loss: 5.2194037
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.093778610229492
Epoch: 38, Steps: 4 | Train Loss: 0.3316401 Vali Loss: nan Test Loss: 5.2149467
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.1835951805114746
Epoch: 39, Steps: 4 | Train Loss: 0.3308371 Vali Loss: nan Test Loss: 5.2139258
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.152801990509033
Epoch: 40, Steps: 4 | Train Loss: 0.3282772 Vali Loss: nan Test Loss: 5.1945329
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.300100088119507
Epoch: 41, Steps: 4 | Train Loss: 0.3368623 Vali Loss: nan Test Loss: 5.2216926
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.274916648864746
Epoch: 42, Steps: 4 | Train Loss: 0.3342030 Vali Loss: nan Test Loss: 5.2070565
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 2.3921070098876953
Epoch: 43, Steps: 4 | Train Loss: 0.3377033 Vali Loss: nan Test Loss: 5.2035580
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 2.1183764934539795
Epoch: 44, Steps: 4 | Train Loss: 0.3349848 Vali Loss: nan Test Loss: 5.1980810
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 2.164022445678711
Epoch: 45, Steps: 4 | Train Loss: 0.3231779 Vali Loss: nan Test Loss: 5.2083826
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 2.17362642288208
Epoch: 46, Steps: 4 | Train Loss: 0.3352999 Vali Loss: nan Test Loss: 5.2124157
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.3257014751434326
Epoch: 47, Steps: 4 | Train Loss: 0.3376512 Vali Loss: nan Test Loss: 5.2051630
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 2.104172706604004
Epoch: 48, Steps: 4 | Train Loss: 0.3393729 Vali Loss: nan Test Loss: 5.2162905
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 2.220656394958496
Epoch: 49, Steps: 4 | Train Loss: 0.3316767 Vali Loss: nan Test Loss: 5.2117591
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 2.081031560897827
Epoch: 50, Steps: 4 | Train Loss: 0.3278381 Vali Loss: nan Test Loss: 5.2030430
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.126523971557617
Epoch: 51, Steps: 4 | Train Loss: 0.3332171 Vali Loss: nan Test Loss: 5.2064047
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.2312185764312744
Epoch: 52, Steps: 4 | Train Loss: 0.3330336 Vali Loss: nan Test Loss: 5.2116189
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.0736584663391113
Epoch: 53, Steps: 4 | Train Loss: 0.3320123 Vali Loss: nan Test Loss: 5.2260356
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 2.427790880203247
Epoch: 54, Steps: 4 | Train Loss: 0.3337529 Vali Loss: nan Test Loss: 5.2113152
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 2.2125604152679443
Epoch: 55, Steps: 4 | Train Loss: 0.3255839 Vali Loss: nan Test Loss: 5.1992316
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.2820608615875244
Epoch: 56, Steps: 4 | Train Loss: 0.3414436 Vali Loss: nan Test Loss: 5.2246294
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 2.2242531776428223
Epoch: 57, Steps: 4 | Train Loss: 0.3323993 Vali Loss: nan Test Loss: 5.2357111
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 2.0923023223876953
Epoch: 58, Steps: 4 | Train Loss: 0.3433766 Vali Loss: nan Test Loss: 5.2085409
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 2.1375951766967773
Epoch: 59, Steps: 4 | Train Loss: 0.3257839 Vali Loss: nan Test Loss: 5.2147903
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 2.0801663398742676
Epoch: 60, Steps: 4 | Train Loss: 0.3313174 Vali Loss: nan Test Loss: 5.2151175
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 2.1178433895111084
Epoch: 61, Steps: 4 | Train Loss: 0.3319329 Vali Loss: nan Test Loss: 5.2240443
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 2.081580400466919
Epoch: 62, Steps: 4 | Train Loss: 0.3303284 Vali Loss: nan Test Loss: 5.1994586
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 2.2536048889160156
Epoch: 63, Steps: 4 | Train Loss: 0.3285336 Vali Loss: nan Test Loss: 5.2103353
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 2.1378705501556396
Epoch: 64, Steps: 4 | Train Loss: 0.3309079 Vali Loss: nan Test Loss: 5.2186317
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.2777671813964844
Epoch: 65, Steps: 4 | Train Loss: 0.3285888 Vali Loss: nan Test Loss: 5.2043738
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 2.2849175930023193
Epoch: 66, Steps: 4 | Train Loss: 0.3354254 Vali Loss: nan Test Loss: 5.2201681
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.065260171890259
Epoch: 67, Steps: 4 | Train Loss: 0.3317169 Vali Loss: nan Test Loss: 5.2249188
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 2.4106571674346924
Epoch: 68, Steps: 4 | Train Loss: 0.3238891 Vali Loss: nan Test Loss: 5.2163796
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 2.046370029449463
Epoch: 69, Steps: 4 | Train Loss: 0.3264996 Vali Loss: nan Test Loss: 5.1832471
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.3014447689056396
Epoch: 70, Steps: 4 | Train Loss: 0.3257826 Vali Loss: nan Test Loss: 5.2051110
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 2.2963874340057373
Epoch: 71, Steps: 4 | Train Loss: 0.3341693 Vali Loss: nan Test Loss: 5.2134151
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.362705945968628
Epoch: 72, Steps: 4 | Train Loss: 0.3257024 Vali Loss: nan Test Loss: 5.1873875
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 2.1317837238311768
Epoch: 73, Steps: 4 | Train Loss: 0.3349594 Vali Loss: nan Test Loss: 5.2051072
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.087524890899658
Epoch: 74, Steps: 4 | Train Loss: 0.3264204 Vali Loss: nan Test Loss: 5.2079501
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 2.133272171020508
Epoch: 75, Steps: 4 | Train Loss: 0.3321213 Vali Loss: nan Test Loss: 5.2088428
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 2.1829564571380615
Epoch: 76, Steps: 4 | Train Loss: 0.3343036 Vali Loss: nan Test Loss: 5.2088938
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 2.2931935787200928
Epoch: 77, Steps: 4 | Train Loss: 0.3209859 Vali Loss: nan Test Loss: 5.2189245
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 2.1184067726135254
Epoch: 78, Steps: 4 | Train Loss: 0.3345799 Vali Loss: nan Test Loss: 5.2121983
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 2.1347548961639404
Epoch: 79, Steps: 4 | Train Loss: 0.3337147 Vali Loss: nan Test Loss: 5.2092452
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.0941858291625977
Epoch: 80, Steps: 4 | Train Loss: 0.3392942 Vali Loss: nan Test Loss: 5.2179036
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 2.113919496536255
Epoch: 81, Steps: 4 | Train Loss: 0.3273368 Vali Loss: nan Test Loss: 5.2094421
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.2727482318878174
Epoch: 82, Steps: 4 | Train Loss: 0.3296239 Vali Loss: nan Test Loss: 5.2161241
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 2.176704168319702
Epoch: 83, Steps: 4 | Train Loss: 0.3224725 Vali Loss: nan Test Loss: 5.2059655
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 2.2929916381835938
Epoch: 84, Steps: 4 | Train Loss: 0.3419119 Vali Loss: nan Test Loss: 5.2055378
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 2.0728418827056885
Epoch: 85, Steps: 4 | Train Loss: 0.3198198 Vali Loss: nan Test Loss: 5.2006226
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 2.1995251178741455
Epoch: 86, Steps: 4 | Train Loss: 0.3284824 Vali Loss: nan Test Loss: 5.2034540
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.214693307876587
Epoch: 87, Steps: 4 | Train Loss: 0.3305769 Vali Loss: nan Test Loss: 5.1966758
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 2.18224835395813
Epoch: 88, Steps: 4 | Train Loss: 0.3311625 Vali Loss: nan Test Loss: 5.1996255
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.1143648624420166
Epoch: 89, Steps: 4 | Train Loss: 0.3348910 Vali Loss: nan Test Loss: 5.2218022
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 2.060887575149536
Epoch: 90, Steps: 4 | Train Loss: 0.3210806 Vali Loss: nan Test Loss: 5.2182212
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 2.0748908519744873
Epoch: 91, Steps: 4 | Train Loss: 0.3186221 Vali Loss: nan Test Loss: 5.2093468
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 2.232576370239258
Epoch: 92, Steps: 4 | Train Loss: 0.3319135 Vali Loss: nan Test Loss: 5.2042260
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.3270599842071533
Epoch: 93, Steps: 4 | Train Loss: 0.3319272 Vali Loss: nan Test Loss: 5.2064095
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 2.003157377243042
Epoch: 94, Steps: 4 | Train Loss: 0.3210277 Vali Loss: nan Test Loss: 5.2105727
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.0578601360321045
Epoch: 95, Steps: 4 | Train Loss: 0.3320982 Vali Loss: nan Test Loss: 5.2151194
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 2.169771194458008
Epoch: 96, Steps: 4 | Train Loss: 0.3288625 Vali Loss: nan Test Loss: 5.2114372
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.0016071796417236
Epoch: 97, Steps: 4 | Train Loss: 0.3255747 Vali Loss: nan Test Loss: 5.2213387
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 2.749758005142212
Epoch: 98, Steps: 4 | Train Loss: 0.3290934 Vali Loss: nan Test Loss: 5.2014160
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 2.052889823913574
Epoch: 99, Steps: 4 | Train Loss: 0.3353534 Vali Loss: nan Test Loss: 5.2108831
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 2.2424025535583496
Epoch: 100, Steps: 4 | Train Loss: 0.3278759 Vali Loss: nan Test Loss: 5.2067881
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : ili_36_48_Informer_custom_ftM_sl36_ll18_pl48_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 146
mse:5.222315311431885, mae:1.5774071216583252, rse:1.0976581573486328
