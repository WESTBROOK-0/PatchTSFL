Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='Informer', model_id='ili_36_36', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=36, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ili_36_36_Informer_custom_ftM_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 605
val 62
test 158
Epoch: 1 cost time: 1.9750308990478516
Epoch: 1, Steps: 4 | Train Loss: 1.3751594 Vali Loss: nan Test Loss: 7.8389487
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.0019707679748535
Epoch: 2, Steps: 4 | Train Loss: 1.0129963 Vali Loss: nan Test Loss: 5.2006068
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 1.863215446472168
Epoch: 3, Steps: 4 | Train Loss: 0.8622956 Vali Loss: nan Test Loss: 4.6386251
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.220473051071167
Epoch: 4, Steps: 4 | Train Loss: 0.7595967 Vali Loss: nan Test Loss: 5.1399641
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 1.9786500930786133
Epoch: 5, Steps: 4 | Train Loss: 0.6860326 Vali Loss: nan Test Loss: 5.0667748
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 1.786257266998291
Epoch: 6, Steps: 4 | Train Loss: 0.6465906 Vali Loss: nan Test Loss: 4.6909604
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.1633026599884033
Epoch: 7, Steps: 4 | Train Loss: 0.5762439 Vali Loss: nan Test Loss: 4.7819481
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.094534158706665
Epoch: 8, Steps: 4 | Train Loss: 0.5713876 Vali Loss: nan Test Loss: 4.9936776
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 1.8785014152526855
Epoch: 9, Steps: 4 | Train Loss: 0.5087997 Vali Loss: nan Test Loss: 5.1246095
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.207026958465576
Epoch: 10, Steps: 4 | Train Loss: 0.4723413 Vali Loss: nan Test Loss: 5.1395097
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.195507764816284
Epoch: 11, Steps: 4 | Train Loss: 0.4798301 Vali Loss: nan Test Loss: 5.2452097
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.062596559524536
Epoch: 12, Steps: 4 | Train Loss: 0.4159281 Vali Loss: nan Test Loss: 5.3899646
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.1713716983795166
Epoch: 13, Steps: 4 | Train Loss: 0.4305199 Vali Loss: nan Test Loss: 5.4883251
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 1.7691431045532227
Epoch: 14, Steps: 4 | Train Loss: 0.4064201 Vali Loss: nan Test Loss: 5.3433309
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 1.9915821552276611
Epoch: 15, Steps: 4 | Train Loss: 0.4010208 Vali Loss: nan Test Loss: 5.3568358
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 1.9449243545532227
Epoch: 16, Steps: 4 | Train Loss: 0.3964087 Vali Loss: nan Test Loss: 5.4294095
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.486279010772705
Epoch: 17, Steps: 4 | Train Loss: 0.3788262 Vali Loss: nan Test Loss: 5.4437075
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.056037664413452
Epoch: 18, Steps: 4 | Train Loss: 0.3755324 Vali Loss: nan Test Loss: 5.3487763
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.334644317626953
Epoch: 19, Steps: 4 | Train Loss: 0.3498888 Vali Loss: nan Test Loss: 5.3242335
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.138472318649292
Epoch: 20, Steps: 4 | Train Loss: 0.3558264 Vali Loss: nan Test Loss: 5.4158802
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.125300407409668
Epoch: 21, Steps: 4 | Train Loss: 0.3637066 Vali Loss: nan Test Loss: 5.4565940
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 1.975618600845337
Epoch: 22, Steps: 4 | Train Loss: 0.3469076 Vali Loss: nan Test Loss: 5.4277110
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.1430838108062744
Epoch: 23, Steps: 4 | Train Loss: 0.3523648 Vali Loss: nan Test Loss: 5.3591285
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.0007424354553223
Epoch: 24, Steps: 4 | Train Loss: 0.3499283 Vali Loss: nan Test Loss: 5.3027620
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 1.989213228225708
Epoch: 25, Steps: 4 | Train Loss: 0.3522112 Vali Loss: nan Test Loss: 5.3218784
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 1.989124059677124
Epoch: 26, Steps: 4 | Train Loss: 0.3409796 Vali Loss: nan Test Loss: 5.3401871
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 1.9598333835601807
Epoch: 27, Steps: 4 | Train Loss: 0.3302972 Vali Loss: nan Test Loss: 5.3767099
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 1.9775922298431396
Epoch: 28, Steps: 4 | Train Loss: 0.3374851 Vali Loss: nan Test Loss: 5.3169084
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 1.9909915924072266
Epoch: 29, Steps: 4 | Train Loss: 0.3240134 Vali Loss: nan Test Loss: 5.2847743
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.0473811626434326
Epoch: 30, Steps: 4 | Train Loss: 0.3355079 Vali Loss: nan Test Loss: 5.2319560
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.113074541091919
Epoch: 31, Steps: 4 | Train Loss: 0.3283993 Vali Loss: nan Test Loss: 5.2179742
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.232428550720215
Epoch: 32, Steps: 4 | Train Loss: 0.3395325 Vali Loss: nan Test Loss: 5.2517638
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.168765068054199
Epoch: 33, Steps: 4 | Train Loss: 0.3225510 Vali Loss: nan Test Loss: 5.2630038
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.052025079727173
Epoch: 34, Steps: 4 | Train Loss: 0.3368645 Vali Loss: nan Test Loss: 5.2779303
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.07008695602417
Epoch: 35, Steps: 4 | Train Loss: 0.3311593 Vali Loss: nan Test Loss: 5.3052597
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 1.9516832828521729
Epoch: 36, Steps: 4 | Train Loss: 0.3247538 Vali Loss: nan Test Loss: 5.2832155
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.0245254039764404
Epoch: 37, Steps: 4 | Train Loss: 0.3272966 Vali Loss: nan Test Loss: 5.2653637
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.1923930644989014
Epoch: 38, Steps: 4 | Train Loss: 0.3281695 Vali Loss: nan Test Loss: 5.2365780
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 1.9209794998168945
Epoch: 39, Steps: 4 | Train Loss: 0.3244158 Vali Loss: nan Test Loss: 5.2542162
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.129469156265259
Epoch: 40, Steps: 4 | Train Loss: 0.3237383 Vali Loss: nan Test Loss: 5.2439795
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.078240394592285
Epoch: 41, Steps: 4 | Train Loss: 0.3102546 Vali Loss: nan Test Loss: 5.2269487
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.297130823135376
Epoch: 42, Steps: 4 | Train Loss: 0.3316500 Vali Loss: nan Test Loss: 5.2495456
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 1.9227051734924316
Epoch: 43, Steps: 4 | Train Loss: 0.3245081 Vali Loss: nan Test Loss: 5.2546787
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 2.0718958377838135
Epoch: 44, Steps: 4 | Train Loss: 0.3200987 Vali Loss: nan Test Loss: 5.2716675
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 2.4148550033569336
Epoch: 45, Steps: 4 | Train Loss: 0.3176709 Vali Loss: nan Test Loss: 5.2645135
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 2.01003098487854
Epoch: 46, Steps: 4 | Train Loss: 0.3290811 Vali Loss: nan Test Loss: 5.2612352
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.030785322189331
Epoch: 47, Steps: 4 | Train Loss: 0.3256595 Vali Loss: nan Test Loss: 5.2596021
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 1.991708517074585
Epoch: 48, Steps: 4 | Train Loss: 0.3157355 Vali Loss: nan Test Loss: 5.2725434
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 2.080805778503418
Epoch: 49, Steps: 4 | Train Loss: 0.3173458 Vali Loss: nan Test Loss: 5.2563310
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 2.062549352645874
Epoch: 50, Steps: 4 | Train Loss: 0.3198008 Vali Loss: nan Test Loss: 5.2508097
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.2422661781311035
Epoch: 51, Steps: 4 | Train Loss: 0.3039364 Vali Loss: nan Test Loss: 5.2580972
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.2057619094848633
Epoch: 52, Steps: 4 | Train Loss: 0.3137456 Vali Loss: nan Test Loss: 5.2486386
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.026822805404663
Epoch: 53, Steps: 4 | Train Loss: 0.3240805 Vali Loss: nan Test Loss: 5.2535257
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 1.9076054096221924
Epoch: 54, Steps: 4 | Train Loss: 0.3350021 Vali Loss: nan Test Loss: 5.2595348
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 1.9710214138031006
Epoch: 55, Steps: 4 | Train Loss: 0.3085819 Vali Loss: nan Test Loss: 5.2446523
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.0225374698638916
Epoch: 56, Steps: 4 | Train Loss: 0.3159566 Vali Loss: nan Test Loss: 5.2405367
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 2.2807071208953857
Epoch: 57, Steps: 4 | Train Loss: 0.3220932 Vali Loss: nan Test Loss: 5.2346096
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 1.9577150344848633
Epoch: 58, Steps: 4 | Train Loss: 0.3278361 Vali Loss: nan Test Loss: 5.2591124
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 1.8170115947723389
Epoch: 59, Steps: 4 | Train Loss: 0.3145626 Vali Loss: nan Test Loss: 5.2459927
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 1.9697844982147217
Epoch: 60, Steps: 4 | Train Loss: 0.3300008 Vali Loss: nan Test Loss: 5.2505393
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 2.0047314167022705
Epoch: 61, Steps: 4 | Train Loss: 0.3214541 Vali Loss: nan Test Loss: 5.2626729
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 1.9615931510925293
Epoch: 62, Steps: 4 | Train Loss: 0.3037119 Vali Loss: nan Test Loss: 5.2806649
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 2.17230486869812
Epoch: 63, Steps: 4 | Train Loss: 0.3200107 Vali Loss: nan Test Loss: 5.2493844
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 1.9470632076263428
Epoch: 64, Steps: 4 | Train Loss: 0.3116324 Vali Loss: nan Test Loss: 5.2422686
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.1266069412231445
Epoch: 65, Steps: 4 | Train Loss: 0.3220692 Vali Loss: nan Test Loss: 5.2565360
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 1.9837462902069092
Epoch: 66, Steps: 4 | Train Loss: 0.3210453 Vali Loss: nan Test Loss: 5.2550340
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.1793437004089355
Epoch: 67, Steps: 4 | Train Loss: 0.3115744 Vali Loss: nan Test Loss: 5.2557092
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 1.809053897857666
Epoch: 68, Steps: 4 | Train Loss: 0.3122407 Vali Loss: nan Test Loss: 5.2481356
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 1.8349530696868896
Epoch: 69, Steps: 4 | Train Loss: 0.3019585 Vali Loss: nan Test Loss: 5.2413082
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.1020724773406982
Epoch: 70, Steps: 4 | Train Loss: 0.3145986 Vali Loss: nan Test Loss: 5.2525215
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 1.8319597244262695
Epoch: 71, Steps: 4 | Train Loss: 0.3207599 Vali Loss: nan Test Loss: 5.2516317
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.0681352615356445
Epoch: 72, Steps: 4 | Train Loss: 0.3120165 Vali Loss: nan Test Loss: 5.2388506
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 2.259415626525879
Epoch: 73, Steps: 4 | Train Loss: 0.3071919 Vali Loss: nan Test Loss: 5.2680798
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.318932294845581
Epoch: 74, Steps: 4 | Train Loss: 0.3177159 Vali Loss: nan Test Loss: 5.2435255
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 1.8343665599822998
Epoch: 75, Steps: 4 | Train Loss: 0.3004740 Vali Loss: nan Test Loss: 5.2449145
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 2.1441540718078613
Epoch: 76, Steps: 4 | Train Loss: 0.3116508 Vali Loss: nan Test Loss: 5.2420735
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 1.8787550926208496
Epoch: 77, Steps: 4 | Train Loss: 0.3199512 Vali Loss: nan Test Loss: 5.2555790
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 1.8663816452026367
Epoch: 78, Steps: 4 | Train Loss: 0.3155250 Vali Loss: nan Test Loss: 5.2511454
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 1.9551177024841309
Epoch: 79, Steps: 4 | Train Loss: 0.3265401 Vali Loss: nan Test Loss: 5.2341800
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.1371662616729736
Epoch: 80, Steps: 4 | Train Loss: 0.3096213 Vali Loss: nan Test Loss: 5.2478127
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 1.9762465953826904
Epoch: 81, Steps: 4 | Train Loss: 0.3090534 Vali Loss: nan Test Loss: 5.2432566
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.1565260887145996
Epoch: 82, Steps: 4 | Train Loss: 0.3172205 Vali Loss: nan Test Loss: 5.2725306
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 1.9858558177947998
Epoch: 83, Steps: 4 | Train Loss: 0.3149022 Vali Loss: nan Test Loss: 5.2195706
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 2.1738595962524414
Epoch: 84, Steps: 4 | Train Loss: 0.3150768 Vali Loss: nan Test Loss: 5.2455540
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 2.2012388706207275
Epoch: 85, Steps: 4 | Train Loss: 0.3114598 Vali Loss: nan Test Loss: 5.2296009
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 1.9657924175262451
Epoch: 86, Steps: 4 | Train Loss: 0.3180178 Vali Loss: nan Test Loss: 5.2459979
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.1143569946289062
Epoch: 87, Steps: 4 | Train Loss: 0.3144038 Vali Loss: nan Test Loss: 5.2653651
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 1.9423410892486572
Epoch: 88, Steps: 4 | Train Loss: 0.3109757 Vali Loss: nan Test Loss: 5.2454414
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.1851437091827393
Epoch: 89, Steps: 4 | Train Loss: 0.3116426 Vali Loss: nan Test Loss: 5.2492251
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 2.08166766166687
Epoch: 90, Steps: 4 | Train Loss: 0.3210130 Vali Loss: nan Test Loss: 5.2336564
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 2.0418686866760254
Epoch: 91, Steps: 4 | Train Loss: 0.3094960 Vali Loss: nan Test Loss: 5.2443404
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 2.0187225341796875
Epoch: 92, Steps: 4 | Train Loss: 0.3120922 Vali Loss: nan Test Loss: 5.2377028
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.0898032188415527
Epoch: 93, Steps: 4 | Train Loss: 0.3149329 Vali Loss: nan Test Loss: 5.2597151
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 2.070565938949585
Epoch: 94, Steps: 4 | Train Loss: 0.3121808 Vali Loss: nan Test Loss: 5.2604885
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.08784556388855
Epoch: 95, Steps: 4 | Train Loss: 0.3185887 Vali Loss: nan Test Loss: 5.2377920
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 2.205411195755005
Epoch: 96, Steps: 4 | Train Loss: 0.3110865 Vali Loss: nan Test Loss: 5.2660422
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.228388547897339
Epoch: 97, Steps: 4 | Train Loss: 0.3240106 Vali Loss: nan Test Loss: 5.2572632
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 1.9499454498291016
Epoch: 98, Steps: 4 | Train Loss: 0.3134268 Vali Loss: nan Test Loss: 5.2435088
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 2.1907567977905273
Epoch: 99, Steps: 4 | Train Loss: 0.3143916 Vali Loss: nan Test Loss: 5.2487760
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 2.044591188430786
Epoch: 100, Steps: 4 | Train Loss: 0.3138748 Vali Loss: nan Test Loss: 5.2483358
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : ili_36_36_Informer_custom_ftM_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
mse:5.268721580505371, mae:1.5842065811157227, rse:1.1097052097320557
