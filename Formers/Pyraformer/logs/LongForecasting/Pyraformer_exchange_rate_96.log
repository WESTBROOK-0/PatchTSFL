[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=128, d_inner_hid=512, d_k=128, d_model=256, d_v=128, data='exchange', data_path='exchange_rate.csv', dec_in=8, decoder='FC', dropout=0.05, embed_type='CustomEmbedding', enc_in=8, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=1e-05, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=96, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 5260800
train 5120
test 1422
[ Epoch 1 ]
  - (Training) MSE:  1.08199elapse: 0.055 min
(1422, 96, 8)
test shape:(1422, 96, 8)
Epoch 0, mse:1.8648961782455444, mae:1.136723279953003, rmse:1.3656120300292969, mape:3.274303436279297, mspe:3093.119384765625
[ Epoch 2 ]
  - (Training) MSE:  0.59008elapse: 0.057 min
(1422, 96, 8)
test shape:(1422, 96, 8)
Epoch 1, mse:1.7602170705795288, mae:1.1086854934692383, rmse:1.3267316818237305, mape:3.3404200077056885, mspe:3261.098876953125
[ Epoch 3 ]
  - (Training) MSE:  0.56733elapse: 0.055 min
(1422, 96, 8)
test shape:(1422, 96, 8)
Epoch 2, mse:1.7505320310592651, mae:1.1059221029281616, rmse:1.3230767250061035, mape:3.3541667461395264, mspe:3289.470703125
[ Epoch 4 ]
  - (Training) MSE:  0.56474elapse: 0.055 min
(1422, 96, 8)
test shape:(1422, 96, 8)
Epoch 3, mse:1.7486720085144043, mae:1.1045351028442383, rmse:1.322373628616333, mape:3.3294434547424316, mspe:3236.544677734375
[ Epoch 5 ]
  - (Training) MSE:  0.56496elapse: 0.054 min
(1422, 96, 8)
test shape:(1422, 96, 8)
Epoch 4, mse:1.7478015422821045, mae:1.1054275035858154, rmse:1.3220444917678833, mape:3.3623082637786865, mspe:3316.683837890625
Iteration best metrics: [1.7478015422821045, 1.1054275035858154, 1.3220444917678833, 3.3623082637786865, 3316.683837890625]
Average Metrics: [1.74780154e+00 1.10542750e+00 1.32204449e+00 3.36230826e+00
 3.31668384e+03]
