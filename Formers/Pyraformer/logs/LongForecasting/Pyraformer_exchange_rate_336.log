[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=128, d_inner_hid=512, d_k=128, d_model=256, d_v=128, data='exchange', data_path='exchange_rate.csv', dec_in=8, decoder='FC', dropout=0.05, embed_type='CustomEmbedding', enc_in=8, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=1e-05, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=336, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 7226880
train 4880
test 1182
[ Epoch 1 ]
  - (Training) MSE:  0.98168elapse: 0.057 min
(1182, 336, 8)
test shape:(1182, 336, 8)
Epoch 0, mse:2.101497173309326, mae:1.20693039894104, rmse:1.4496541023254395, mape:2.9956512451171875, mspe:2351.89306640625
[ Epoch 2 ]
  - (Training) MSE:  0.64144elapse: 0.057 min
(1182, 336, 8)
test shape:(1182, 336, 8)
Epoch 1, mse:1.9931126832962036, mae:1.181579351425171, rmse:1.4117764234542847, mape:3.1843082904815674, mspe:2713.65185546875
[ Epoch 3 ]
  - (Training) MSE:  0.61726elapse: 0.059 min
(1182, 336, 8)
test shape:(1182, 336, 8)
Epoch 2, mse:1.9829360246658325, mae:1.1790753602981567, rmse:1.4081676006317139, mape:3.2105724811553955, mspe:2766.78369140625
[ Epoch 4 ]
  - (Training) MSE:  0.61852elapse: 0.058 min
(1182, 336, 8)
test shape:(1182, 336, 8)
Epoch 3, mse:1.9833747148513794, mae:1.1794041395187378, rmse:1.4083234071731567, mape:3.1923768520355225, mspe:2725.685546875
[ Epoch 5 ]
  - (Training) MSE:  0.61767elapse: 0.058 min
(1182, 336, 8)
test shape:(1182, 336, 8)
Epoch 4, mse:1.981429934501648, mae:1.1786643266677856, rmse:1.4076327085494995, mape:3.2106146812438965, mspe:2766.52978515625
Iteration best metrics: [1.981429934501648, 1.1786643266677856, 1.4076327085494995, 3.2106146812438965, 2766.52978515625]
Average Metrics: [1.98142993e+00 1.17866433e+00 1.40763271e+00 3.21061468e+00
 2.76652979e+03]
