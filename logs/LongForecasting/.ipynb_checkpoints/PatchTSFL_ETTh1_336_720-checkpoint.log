Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=128, d_layers=1, d_model=16, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.3, e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', model='PatchTSFL', model_id='336_720', moving_avg=25, n_heads=4, num_workers=4, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=720, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
fourier enhanced block used!
modes=0, index=[]
>>>>>>>start training : 336_720_PatchTSFL_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
Epoch: 1 cost time: 1.2495286464691162
Epoch: 1, Steps: 59 | Train Loss: 0.7522417 Vali Loss: 1.8668870 Test Loss: 0.6972634
Validation loss decreased (inf --> 1.866887).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.3082594871520996
Epoch: 2, Steps: 59 | Train Loss: 0.7524756 Vali Loss: 1.8631499 Test Loss: 0.6982265
Validation loss decreased (1.866887 --> 1.863150).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 1.3312230110168457
Epoch: 3, Steps: 59 | Train Loss: 0.7519525 Vali Loss: 1.8658311 Test Loss: 0.6992049
EarlyStopping counter: 1 out of 100
Updating learning rate to 0.0001
Epoch: 4 cost time: 1.1917457580566406
Epoch: 4, Steps: 59 | Train Loss: 0.7513049 Vali Loss: 1.8598704 Test Loss: 0.7001369
Validation loss decreased (1.863150 --> 1.859870).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 1.218876600265503
Epoch: 5, Steps: 59 | Train Loss: 0.7510370 Vali Loss: 1.8638886 Test Loss: 0.7010179
EarlyStopping counter: 1 out of 100
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 1.3313934803009033
Epoch: 6, Steps: 59 | Train Loss: 0.7510124 Vali Loss: 1.8574126 Test Loss: 0.7017736
Validation loss decreased (1.859870 --> 1.857413).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 1.2463419437408447
Epoch: 7, Steps: 59 | Train Loss: 0.7506722 Vali Loss: 1.8622670 Test Loss: 0.7024281
EarlyStopping counter: 1 out of 100
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 1.3236393928527832
Epoch: 8, Steps: 59 | Train Loss: 0.7502369 Vali Loss: 1.8632096 Test Loss: 0.7030386
EarlyStopping counter: 2 out of 100
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 1.330219030380249
Epoch: 9, Steps: 59 | Train Loss: 0.7503606 Vali Loss: 1.8535535 Test Loss: 0.7035760
Validation loss decreased (1.857413 --> 1.853554).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 1.3886919021606445
Epoch: 10, Steps: 59 | Train Loss: 0.7500402 Vali Loss: 1.8525021 Test Loss: 0.7040303
Validation loss decreased (1.853554 --> 1.852502).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 1.2248477935791016
Epoch: 11, Steps: 59 | Train Loss: 0.7500055 Vali Loss: 1.8584259 Test Loss: 0.7044503
EarlyStopping counter: 1 out of 100
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 1.1937384605407715
Epoch: 12, Steps: 59 | Train Loss: 0.7499221 Vali Loss: 1.8527834 Test Loss: 0.7048335
EarlyStopping counter: 2 out of 100
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 1.198155403137207
Epoch: 13, Steps: 59 | Train Loss: 0.7500253 Vali Loss: 1.8568404 Test Loss: 0.7051741
EarlyStopping counter: 3 out of 100
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 1.2414913177490234
Epoch: 14, Steps: 59 | Train Loss: 0.7499907 Vali Loss: 1.8572289 Test Loss: 0.7054631
EarlyStopping counter: 4 out of 100
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 1.2301511764526367
Epoch: 15, Steps: 59 | Train Loss: 0.7498528 Vali Loss: 1.8531513 Test Loss: 0.7057304
EarlyStopping counter: 5 out of 100
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 1.3037614822387695
Epoch: 16, Steps: 59 | Train Loss: 0.7495318 Vali Loss: 1.8527999 Test Loss: 0.7059789
EarlyStopping counter: 6 out of 100
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 1.4604439735412598
Epoch: 17, Steps: 59 | Train Loss: 0.7497812 Vali Loss: 1.8548503 Test Loss: 0.7061935
EarlyStopping counter: 7 out of 100
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 1.3324706554412842
Epoch: 18, Steps: 59 | Train Loss: 0.7497705 Vali Loss: 1.8560311 Test Loss: 0.7063837
EarlyStopping counter: 8 out of 100
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 1.298875093460083
Epoch: 19, Steps: 59 | Train Loss: 0.7492403 Vali Loss: 1.8532860 Test Loss: 0.7065594
EarlyStopping counter: 9 out of 100
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 1.2648496627807617
Epoch: 20, Steps: 59 | Train Loss: 0.7493131 Vali Loss: 1.8523352 Test Loss: 0.7067201
Validation loss decreased (1.852502 --> 1.852335).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 1.1996889114379883
Epoch: 21, Steps: 59 | Train Loss: 0.7493853 Vali Loss: 1.8476150 Test Loss: 0.7068648
Validation loss decreased (1.852335 --> 1.847615).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 1.1713082790374756
Epoch: 22, Steps: 59 | Train Loss: 0.7492887 Vali Loss: 1.8520882 Test Loss: 0.7069851
EarlyStopping counter: 1 out of 100
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 1.2490971088409424
Epoch: 23, Steps: 59 | Train Loss: 0.7497163 Vali Loss: 1.8540943 Test Loss: 0.7071074
EarlyStopping counter: 2 out of 100
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 1.3928310871124268
Epoch: 24, Steps: 59 | Train Loss: 0.7493392 Vali Loss: 1.8515267 Test Loss: 0.7072119
EarlyStopping counter: 3 out of 100
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 1.1811392307281494
Epoch: 25, Steps: 59 | Train Loss: 0.7496807 Vali Loss: 1.8548375 Test Loss: 0.7073041
EarlyStopping counter: 4 out of 100
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 1.2456603050231934
Epoch: 26, Steps: 59 | Train Loss: 0.7494418 Vali Loss: 1.8550072 Test Loss: 0.7073851
EarlyStopping counter: 5 out of 100
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 1.2547962665557861
Epoch: 27, Steps: 59 | Train Loss: 0.7492344 Vali Loss: 1.8552520 Test Loss: 0.7074633
EarlyStopping counter: 6 out of 100
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 1.207463264465332
Epoch: 28, Steps: 59 | Train Loss: 0.7494096 Vali Loss: 1.8522413 Test Loss: 0.7075313
EarlyStopping counter: 7 out of 100
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 1.185218334197998
Epoch: 29, Steps: 59 | Train Loss: 0.7492880 Vali Loss: 1.8511386 Test Loss: 0.7075897
EarlyStopping counter: 8 out of 100
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 1.4468626976013184
Epoch: 30, Steps: 59 | Train Loss: 0.7491500 Vali Loss: 1.8513905 Test Loss: 0.7076451
EarlyStopping counter: 9 out of 100
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 1.1527738571166992
Epoch: 31, Steps: 59 | Train Loss: 0.7492014 Vali Loss: 1.8569090 Test Loss: 0.7076933
EarlyStopping counter: 10 out of 100
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 1.3245186805725098
Epoch: 32, Steps: 59 | Train Loss: 0.7492110 Vali Loss: 1.8551276 Test Loss: 0.7077394
EarlyStopping counter: 11 out of 100
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 1.280357837677002
Epoch: 33, Steps: 59 | Train Loss: 0.7493749 Vali Loss: 1.8470169 Test Loss: 0.7077780
Validation loss decreased (1.847615 --> 1.847017).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 1.3957412242889404
Epoch: 34, Steps: 59 | Train Loss: 0.7492941 Vali Loss: 1.8534042 Test Loss: 0.7078145
EarlyStopping counter: 1 out of 100
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 1.2438514232635498
Epoch: 35, Steps: 59 | Train Loss: 0.7493356 Vali Loss: 1.8571839 Test Loss: 0.7078476
EarlyStopping counter: 2 out of 100
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 1.2608411312103271
Epoch: 36, Steps: 59 | Train Loss: 0.7493518 Vali Loss: 1.8499675 Test Loss: 0.7078770
EarlyStopping counter: 3 out of 100
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 1.1514225006103516
Epoch: 37, Steps: 59 | Train Loss: 0.7493769 Vali Loss: 1.8525068 Test Loss: 0.7079021
EarlyStopping counter: 4 out of 100
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 1.4595470428466797
Epoch: 38, Steps: 59 | Train Loss: 0.7492551 Vali Loss: 1.8525462 Test Loss: 0.7079269
EarlyStopping counter: 5 out of 100
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 1.281998872756958
Epoch: 39, Steps: 59 | Train Loss: 0.7494675 Vali Loss: 1.8522260 Test Loss: 0.7079490
EarlyStopping counter: 6 out of 100
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 1.302652359008789
Epoch: 40, Steps: 59 | Train Loss: 0.7493869 Vali Loss: 1.8597857 Test Loss: 0.7079680
EarlyStopping counter: 7 out of 100
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 1.2380914688110352
Epoch: 41, Steps: 59 | Train Loss: 0.7493630 Vali Loss: 1.8558280 Test Loss: 0.7079860
EarlyStopping counter: 8 out of 100
Updating learning rate to 1.8248003631400751e-06
