Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=256, d_layers=1, d_model=128, data='ETTm1', data_path='ETTm1.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.2, e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.2, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='TST', model='PatchTST', model_id='336_336', moving_avg=25, n_heads=16, num_workers=4, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.4, pred_len=336, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 336_336_PatchTST_ETTm1_ftM_sl336_ll48_pl336_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4811136
	speed: 0.0514s/iter; left time: 1352.5809s
	iters: 200, epoch: 1 | loss: 0.4351768
	speed: 0.0451s/iter; left time: 1181.5871s
Epoch: 1 cost time: 12.666972160339355
Epoch: 1, Steps: 264 | Train Loss: 0.4978792 Vali Loss: 0.7163687 Test Loss: 0.4307570
Validation loss decreased (inf --> 0.716369).  Saving model ...
Updating learning rate to 4.147995994617984e-06
	iters: 100, epoch: 2 | loss: 0.4095981
	speed: 0.1293s/iter; left time: 3367.0316s
	iters: 200, epoch: 2 | loss: 0.3689741
	speed: 0.0452s/iter; left time: 1172.7335s
Epoch: 2 cost time: 12.619208812713623
Epoch: 2, Steps: 264 | Train Loss: 0.4099036 Vali Loss: 0.6749340 Test Loss: 0.3987184
Validation loss decreased (0.716369 --> 0.674934).  Saving model ...
Updating learning rate to 4.591071361204269e-06
	iters: 100, epoch: 3 | loss: 0.3460692
	speed: 0.1292s/iter; left time: 3328.6244s
	iters: 200, epoch: 3 | loss: 0.3913707
	speed: 0.0452s/iter; left time: 1160.5453s
Epoch: 3 cost time: 12.619923830032349
Epoch: 3, Steps: 264 | Train Loss: 0.3859577 Vali Loss: 0.6629878 Test Loss: 0.3872645
Validation loss decreased (0.674934 --> 0.662988).  Saving model ...
Updating learning rate to 5.3264938756102174e-06
	iters: 100, epoch: 4 | loss: 0.4206491
	speed: 0.1296s/iter; left time: 3306.4022s
	iters: 200, epoch: 4 | loss: 0.3251568
	speed: 0.0453s/iter; left time: 1149.8317s
Epoch: 4 cost time: 12.643102884292603
Epoch: 4, Steps: 264 | Train Loss: 0.3738804 Vali Loss: 0.6559597 Test Loss: 0.3814971
Validation loss decreased (0.662988 --> 0.655960).  Saving model ...
Updating learning rate to 6.349728555065631e-06
	iters: 100, epoch: 5 | loss: 0.3437476
	speed: 0.1316s/iter; left time: 3321.6339s
	iters: 200, epoch: 5 | loss: 0.4011720
	speed: 0.0452s/iter; left time: 1136.8622s
Epoch: 5 cost time: 12.720845460891724
Epoch: 5, Steps: 264 | Train Loss: 0.3672706 Vali Loss: 0.6555135 Test Loss: 0.3778081
Validation loss decreased (0.655960 --> 0.655514).  Saving model ...
Updating learning rate to 7.654465623149092e-06
	iters: 100, epoch: 6 | loss: 0.3835152
	speed: 0.1289s/iter; left time: 3219.1782s
	iters: 200, epoch: 6 | loss: 0.3497559
	speed: 0.0452s/iter; left time: 1124.5820s
Epoch: 6 cost time: 12.615340232849121
Epoch: 6, Steps: 264 | Train Loss: 0.3633199 Vali Loss: 0.6529013 Test Loss: 0.3759545
Validation loss decreased (0.655514 --> 0.652901).  Saving model ...
Updating learning rate to 9.232659419022894e-06
	iters: 100, epoch: 7 | loss: 0.4078688
	speed: 0.1290s/iter; left time: 3188.4511s
	iters: 200, epoch: 7 | loss: 0.3210192
	speed: 0.0453s/iter; left time: 1115.2837s
Epoch: 7 cost time: 12.546510934829712
Epoch: 7, Steps: 264 | Train Loss: 0.3600912 Vali Loss: 0.6544585 Test Loss: 0.3740318
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1074578010998666e-05
	iters: 100, epoch: 8 | loss: 0.3471399
	speed: 0.1277s/iter; left time: 3122.3993s
	iters: 200, epoch: 8 | loss: 0.3522315
	speed: 0.0453s/iter; left time: 1102.9007s
Epoch: 8 cost time: 12.575764894485474
Epoch: 8, Steps: 264 | Train Loss: 0.3574577 Vali Loss: 0.6479731 Test Loss: 0.3735995
Validation loss decreased (0.652901 --> 0.647973).  Saving model ...
Updating learning rate to 1.3168863208492038e-05
	iters: 100, epoch: 9 | loss: 0.3456957
	speed: 0.1276s/iter; left time: 3085.5467s
	iters: 200, epoch: 9 | loss: 0.3745540
	speed: 0.0452s/iter; left time: 1089.7946s
Epoch: 9 cost time: 12.51868987083435
Epoch: 9, Steps: 264 | Train Loss: 0.3542482 Vali Loss: 0.6490912 Test Loss: 0.3702239
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5502600602302323e-05
	iters: 100, epoch: 10 | loss: 0.3409764
	speed: 0.1308s/iter; left time: 3129.1043s
	iters: 200, epoch: 10 | loss: 0.2998146
	speed: 0.0452s/iter; left time: 1077.5398s
Epoch: 10 cost time: 12.70702314376831
Epoch: 10, Steps: 264 | Train Loss: 0.3502459 Vali Loss: 0.6489341 Test Loss: 0.3687176
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.8061399201313948e-05
	iters: 100, epoch: 11 | loss: 0.3048662
	speed: 0.1297s/iter; left time: 3069.0103s
	iters: 200, epoch: 11 | loss: 0.3558401
	speed: 0.0452s/iter; left time: 1065.2855s
Epoch: 11 cost time: 12.633540868759155
Epoch: 11, Steps: 264 | Train Loss: 0.3462639 Vali Loss: 0.6471285 Test Loss: 0.3663141
Validation loss decreased (0.647973 --> 0.647128).  Saving model ...
Updating learning rate to 2.08294801745399e-05
	iters: 100, epoch: 12 | loss: 0.3253465
	speed: 0.1299s/iter; left time: 3039.1033s
	iters: 200, epoch: 12 | loss: 0.3618993
	speed: 0.0453s/iter; left time: 1054.2180s
Epoch: 12 cost time: 12.637706279754639
Epoch: 12, Steps: 264 | Train Loss: 0.3424173 Vali Loss: 0.6406138 Test Loss: 0.3653395
Validation loss decreased (0.647128 --> 0.640614).  Saving model ...
Updating learning rate to 2.378977415127951e-05
	iters: 100, epoch: 13 | loss: 0.3163766
	speed: 0.1290s/iter; left time: 2984.4493s
	iters: 200, epoch: 13 | loss: 0.3981708
	speed: 0.0453s/iter; left time: 1042.4686s
Epoch: 13 cost time: 12.670328617095947
Epoch: 13, Steps: 264 | Train Loss: 0.3395400 Vali Loss: 0.6373891 Test Loss: 0.3644253
Validation loss decreased (0.640614 --> 0.637389).  Saving model ...
Updating learning rate to 2.6924026479389104e-05
	iters: 100, epoch: 14 | loss: 0.3104040
	speed: 0.1314s/iter; left time: 3004.4367s
	iters: 200, epoch: 14 | loss: 0.3656835
	speed: 0.0452s/iter; left time: 1029.5996s
Epoch: 14 cost time: 12.69313359260559
Epoch: 14, Steps: 264 | Train Loss: 0.3367268 Vali Loss: 0.6363085 Test Loss: 0.3648961
Validation loss decreased (0.637389 --> 0.636308).  Saving model ...
Updating learning rate to 3.0212909792590238e-05
	iters: 100, epoch: 15 | loss: 0.3537722
	speed: 0.1288s/iter; left time: 2911.4036s
	iters: 200, epoch: 15 | loss: 0.3525700
	speed: 0.0453s/iter; left time: 1018.9277s
Epoch: 15 cost time: 12.648467302322388
Epoch: 15, Steps: 264 | Train Loss: 0.3342015 Vali Loss: 0.6394014 Test Loss: 0.3654942
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.363614319266957e-05
	iters: 100, epoch: 16 | loss: 0.3437814
	speed: 0.1297s/iter; left time: 2898.4176s
	iters: 200, epoch: 16 | loss: 0.3376918
	speed: 0.0452s/iter; left time: 1005.1617s
Epoch: 16 cost time: 12.636309146881104
Epoch: 16, Steps: 264 | Train Loss: 0.3321828 Vali Loss: 0.6387480 Test Loss: 0.3661234
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.7172617311633196e-05
	iters: 100, epoch: 17 | loss: 0.2953185
	speed: 0.1298s/iter; left time: 2865.6398s
