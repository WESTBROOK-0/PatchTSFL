Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=256, d_layers=1, d_model=128, data='custom', data_path='exchange_rate.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.2, e_layers=3, embed='timeF', embed_type=0, enc_in=8, factor=1, fc_dropout=0.2, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', model='PatchTSFL', model_id='exchange_rate_336_720', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=720, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
fourier enhanced block used!
modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
>>>>>>>start training : exchange_rate_336_720_PatchTSFL_custom_ftM_sl336_ll48_pl720_dm128_nh8_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4256
val 41
test 798
Epoch: 1 cost time: 4.71195387840271
Epoch: 1, Steps: 33 | Train Loss: 1.0785644 Vali Loss: nan Test Loss: 1.1533393
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 4.907210350036621
Epoch: 2, Steps: 33 | Train Loss: 1.0524645 Vali Loss: nan Test Loss: 1.0248128
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 4.886079549789429
Epoch: 3, Steps: 33 | Train Loss: 0.9012477 Vali Loss: nan Test Loss: 0.9078834
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 4.8172523975372314
Epoch: 4, Steps: 33 | Train Loss: 0.8436894 Vali Loss: nan Test Loss: 0.9268632
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 5.145630359649658
Epoch: 5, Steps: 33 | Train Loss: 0.8297255 Vali Loss: nan Test Loss: 0.9052611
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 4.733967065811157
Epoch: 6, Steps: 33 | Train Loss: 0.8211771 Vali Loss: nan Test Loss: 0.9087364
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 4.939626216888428
Epoch: 7, Steps: 33 | Train Loss: 0.8151825 Vali Loss: nan Test Loss: 0.9049732
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 4.898419618606567
Epoch: 8, Steps: 33 | Train Loss: 0.8081965 Vali Loss: nan Test Loss: 0.9087780
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 4.989956855773926
Epoch: 9, Steps: 33 | Train Loss: 0.8037695 Vali Loss: nan Test Loss: 0.9007801
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 4.813852071762085
Epoch: 10, Steps: 33 | Train Loss: 0.8019955 Vali Loss: nan Test Loss: 0.9086721
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 4.915600061416626
Epoch: 11, Steps: 33 | Train Loss: 0.7973041 Vali Loss: nan Test Loss: 0.9094990
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 4.765479564666748
Epoch: 12, Steps: 33 | Train Loss: 0.7948006 Vali Loss: nan Test Loss: 0.9031808
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 5.133086919784546
Epoch: 13, Steps: 33 | Train Loss: 0.7914310 Vali Loss: nan Test Loss: 0.9107663
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 4.9628989696502686
Epoch: 14, Steps: 33 | Train Loss: 0.7896848 Vali Loss: nan Test Loss: 0.9133608
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 4.84906005859375
Epoch: 15, Steps: 33 | Train Loss: 0.7877722 Vali Loss: nan Test Loss: 0.9083717
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 5.02831768989563
Epoch: 16, Steps: 33 | Train Loss: 0.7845676 Vali Loss: nan Test Loss: 0.9109914
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 4.922415018081665
Epoch: 17, Steps: 33 | Train Loss: 0.7819341 Vali Loss: nan Test Loss: 0.9177048
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 5.009157180786133
Epoch: 18, Steps: 33 | Train Loss: 0.7803071 Vali Loss: nan Test Loss: 0.9126343
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 4.966500520706177
Epoch: 19, Steps: 33 | Train Loss: 0.7789367 Vali Loss: nan Test Loss: 0.9128367
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 4.9009504318237305
Epoch: 20, Steps: 33 | Train Loss: 0.7768471 Vali Loss: nan Test Loss: 0.9112208
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 5.272163391113281
Epoch: 21, Steps: 33 | Train Loss: 0.7751148 Vali Loss: nan Test Loss: 0.9120170
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 4.870406866073608
Epoch: 22, Steps: 33 | Train Loss: 0.7730781 Vali Loss: nan Test Loss: 0.9141977
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 4.916827201843262
Epoch: 23, Steps: 33 | Train Loss: 0.7730220 Vali Loss: nan Test Loss: 0.9125204
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 5.045755863189697
Epoch: 24, Steps: 33 | Train Loss: 0.7721324 Vali Loss: nan Test Loss: 0.9162014
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 4.818908929824829
Epoch: 25, Steps: 33 | Train Loss: 0.7688633 Vali Loss: nan Test Loss: 0.9144278
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 4.854763507843018
Epoch: 26, Steps: 33 | Train Loss: 0.7677632 Vali Loss: nan Test Loss: 0.9169559
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 5.061135768890381
Epoch: 27, Steps: 33 | Train Loss: 0.7668693 Vali Loss: nan Test Loss: 0.9171340
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 4.86444354057312
Epoch: 28, Steps: 33 | Train Loss: 0.7665931 Vali Loss: nan Test Loss: 0.9163451
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 5.082196474075317
Epoch: 29, Steps: 33 | Train Loss: 0.7655559 Vali Loss: nan Test Loss: 0.9174953
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 4.85214638710022
Epoch: 30, Steps: 33 | Train Loss: 0.7654805 Vali Loss: nan Test Loss: 0.9186766
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 4.7956907749176025
Epoch: 31, Steps: 33 | Train Loss: 0.7651039 Vali Loss: nan Test Loss: 0.9196105
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 4.7650275230407715
Epoch: 32, Steps: 33 | Train Loss: 0.7642403 Vali Loss: nan Test Loss: 0.9202296
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 5.111984729766846
Epoch: 33, Steps: 33 | Train Loss: 0.7623964 Vali Loss: nan Test Loss: 0.9202083
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 4.8579185009002686
Epoch: 34, Steps: 33 | Train Loss: 0.7633949 Vali Loss: nan Test Loss: 0.9216149
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 5.556097030639648
Epoch: 35, Steps: 33 | Train Loss: 0.7633510 Vali Loss: nan Test Loss: 0.9219274
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 5.012572288513184
Epoch: 36, Steps: 33 | Train Loss: 0.7615005 Vali Loss: nan Test Loss: 0.9219553
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 4.970009803771973
Epoch: 37, Steps: 33 | Train Loss: 0.7614906 Vali Loss: nan Test Loss: 0.9224657
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 4.910353660583496
Epoch: 38, Steps: 33 | Train Loss: 0.7606698 Vali Loss: nan Test Loss: 0.9216349
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 4.967330455780029
Epoch: 39, Steps: 33 | Train Loss: 0.7610090 Vali Loss: nan Test Loss: 0.9226845
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 4.8033058643341064
Epoch: 40, Steps: 33 | Train Loss: 0.7612382 Vali Loss: nan Test Loss: 0.9241279
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 4.785158634185791
Epoch: 41, Steps: 33 | Train Loss: 0.7599644 Vali Loss: nan Test Loss: 0.9237621
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 4.979530334472656
Epoch: 42, Steps: 33 | Train Loss: 0.7588186 Vali Loss: nan Test Loss: 0.9240091
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 4.961902856826782
Epoch: 43, Steps: 33 | Train Loss: 0.7598938 Vali Loss: nan Test Loss: 0.9242290
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 4.935201644897461
Epoch: 44, Steps: 33 | Train Loss: 0.7602408 Vali Loss: nan Test Loss: 0.9240447
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 4.89975643157959
Epoch: 45, Steps: 33 | Train Loss: 0.7595312 Vali Loss: nan Test Loss: 0.9244883
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 5.282618284225464
Epoch: 46, Steps: 33 | Train Loss: 0.7596642 Vali Loss: nan Test Loss: 0.9247821
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 4.829904556274414
Epoch: 47, Steps: 33 | Train Loss: 0.7588645 Vali Loss: nan Test Loss: 0.9248633
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 4.923274517059326
Epoch: 48, Steps: 33 | Train Loss: 0.7575344 Vali Loss: nan Test Loss: 0.9250834
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 4.960980176925659
Epoch: 49, Steps: 33 | Train Loss: 0.7574727 Vali Loss: nan Test Loss: 0.9252687
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 5.023091793060303
Epoch: 50, Steps: 33 | Train Loss: 0.7582368 Vali Loss: nan Test Loss: 0.9253232
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 5.357701778411865
Epoch: 51, Steps: 33 | Train Loss: 0.7588446 Vali Loss: nan Test Loss: 0.9254823
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 4.767504692077637
Epoch: 52, Steps: 33 | Train Loss: 0.7593912 Vali Loss: nan Test Loss: 0.9255380
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 5.089482307434082
Epoch: 53, Steps: 33 | Train Loss: 0.7594814 Vali Loss: nan Test Loss: 0.9257094
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 4.930736064910889
Epoch: 54, Steps: 33 | Train Loss: 0.7588764 Vali Loss: nan Test Loss: 0.9258079
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 5.03902006149292
Epoch: 55, Steps: 33 | Train Loss: 0.7582576 Vali Loss: nan Test Loss: 0.9257829
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 5.000506401062012
Epoch: 56, Steps: 33 | Train Loss: 0.7597034 Vali Loss: nan Test Loss: 0.9257307
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 5.019845962524414
Epoch: 57, Steps: 33 | Train Loss: 0.7574820 Vali Loss: nan Test Loss: 0.9258664
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 4.985079526901245
Epoch: 58, Steps: 33 | Train Loss: 0.7590986 Vali Loss: nan Test Loss: 0.9259396
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 4.93004035949707
Epoch: 59, Steps: 33 | Train Loss: 0.7570220 Vali Loss: nan Test Loss: 0.9259792
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 5.18724799156189
Epoch: 60, Steps: 33 | Train Loss: 0.7591251 Vali Loss: nan Test Loss: 0.9260402
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 5.286916971206665
Epoch: 61, Steps: 33 | Train Loss: 0.7573856 Vali Loss: nan Test Loss: 0.9260338
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 5.026885271072388
Epoch: 62, Steps: 33 | Train Loss: 0.7589541 Vali Loss: nan Test Loss: 0.9260647
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 4.827344655990601
Epoch: 63, Steps: 33 | Train Loss: 0.7587536 Vali Loss: nan Test Loss: 0.9260926
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 4.822320222854614
Epoch: 64, Steps: 33 | Train Loss: 0.7574527 Vali Loss: nan Test Loss: 0.9261107
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 4.932091236114502
Epoch: 65, Steps: 33 | Train Loss: 0.7565195 Vali Loss: nan Test Loss: 0.9260924
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 4.896079063415527
Epoch: 66, Steps: 33 | Train Loss: 0.7587462 Vali Loss: nan Test Loss: 0.9261499
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 4.972795009613037
Epoch: 67, Steps: 33 | Train Loss: 0.7590230 Vali Loss: nan Test Loss: 0.9261494
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 5.0348546504974365
Epoch: 68, Steps: 33 | Train Loss: 0.7591127 Vali Loss: nan Test Loss: 0.9262077
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 5.16752552986145
Epoch: 69, Steps: 33 | Train Loss: 0.7588963 Vali Loss: nan Test Loss: 0.9262187
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 4.937039852142334
Epoch: 70, Steps: 33 | Train Loss: 0.7594023 Vali Loss: nan Test Loss: 0.9262524
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 4.883546352386475
Epoch: 71, Steps: 33 | Train Loss: 0.7581733 Vali Loss: nan Test Loss: 0.9262691
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 5.000010013580322
Epoch: 72, Steps: 33 | Train Loss: 0.7576921 Vali Loss: nan Test Loss: 0.9262822
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 5.053590297698975
Epoch: 73, Steps: 33 | Train Loss: 0.7578536 Vali Loss: nan Test Loss: 0.9262852
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 5.135179281234741
Epoch: 74, Steps: 33 | Train Loss: 0.7579485 Vali Loss: nan Test Loss: 0.9263086
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 4.925227880477905
Epoch: 75, Steps: 33 | Train Loss: 0.7581460 Vali Loss: nan Test Loss: 0.9263065
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 4.883019208908081
Epoch: 76, Steps: 33 | Train Loss: 0.7575905 Vali Loss: nan Test Loss: 0.9263115
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 4.999228239059448
Epoch: 77, Steps: 33 | Train Loss: 0.7586825 Vali Loss: nan Test Loss: 0.9263222
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 4.930309534072876
Epoch: 78, Steps: 33 | Train Loss: 0.7575345 Vali Loss: nan Test Loss: 0.9263278
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 4.894551992416382
Epoch: 79, Steps: 33 | Train Loss: 0.7583384 Vali Loss: nan Test Loss: 0.9263300
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 4.986052989959717
Epoch: 80, Steps: 33 | Train Loss: 0.7592783 Vali Loss: nan Test Loss: 0.9263294
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 4.860766172409058
Epoch: 81, Steps: 33 | Train Loss: 0.7584690 Vali Loss: nan Test Loss: 0.9263385
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 4.981145858764648
Epoch: 82, Steps: 33 | Train Loss: 0.7576045 Vali Loss: nan Test Loss: 0.9263441
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 4.802776098251343
Epoch: 83, Steps: 33 | Train Loss: 0.7585492 Vali Loss: nan Test Loss: 0.9263442
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 4.79695725440979
Epoch: 84, Steps: 33 | Train Loss: 0.7590919 Vali Loss: nan Test Loss: 0.9263465
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 5.055430173873901
Epoch: 85, Steps: 33 | Train Loss: 0.7584501 Vali Loss: nan Test Loss: 0.9263518
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 4.946393728256226
Epoch: 86, Steps: 33 | Train Loss: 0.7583226 Vali Loss: nan Test Loss: 0.9263549
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 4.946276426315308
Epoch: 87, Steps: 33 | Train Loss: 0.7593331 Vali Loss: nan Test Loss: 0.9263546
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 4.825268030166626
Epoch: 88, Steps: 33 | Train Loss: 0.7573386 Vali Loss: nan Test Loss: 0.9263604
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 4.834228277206421
Epoch: 89, Steps: 33 | Train Loss: 0.7581818 Vali Loss: nan Test Loss: 0.9263610
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 4.845929861068726
Epoch: 90, Steps: 33 | Train Loss: 0.7600874 Vali Loss: nan Test Loss: 0.9263623
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 5.07593846321106
Epoch: 91, Steps: 33 | Train Loss: 0.7584485 Vali Loss: nan Test Loss: 0.9263645
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 4.824395656585693
Epoch: 92, Steps: 33 | Train Loss: 0.7580597 Vali Loss: nan Test Loss: 0.9263637
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 4.880284070968628
Epoch: 93, Steps: 33 | Train Loss: 0.7587594 Vali Loss: nan Test Loss: 0.9263636
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 5.0145790576934814
Epoch: 94, Steps: 33 | Train Loss: 0.7581082 Vali Loss: nan Test Loss: 0.9263651
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 4.859273672103882
Epoch: 95, Steps: 33 | Train Loss: 0.7580608 Vali Loss: nan Test Loss: 0.9263666
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 4.743027925491333
Epoch: 96, Steps: 33 | Train Loss: 0.7587086 Vali Loss: nan Test Loss: 0.9263667
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 4.892942905426025
Epoch: 97, Steps: 33 | Train Loss: 0.7582842 Vali Loss: nan Test Loss: 0.9263671
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 5.42888617515564
Epoch: 98, Steps: 33 | Train Loss: 0.7590721 Vali Loss: nan Test Loss: 0.9263685
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 4.971698522567749
Epoch: 99, Steps: 33 | Train Loss: 0.7587789 Vali Loss: nan Test Loss: 0.9263704
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 4.952372312545776
Epoch: 100, Steps: 33 | Train Loss: 0.7589649 Vali Loss: nan Test Loss: 0.9263701
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : exchange_rate_336_720_PatchTSFL_custom_ftM_sl336_ll48_pl720_dm128_nh8_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
mse:0.9263700842857361, mae:0.726780891418457, rse:0.7591131925582886
