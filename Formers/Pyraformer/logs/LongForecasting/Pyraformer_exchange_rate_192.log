[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=128, d_inner_hid=512, d_k=128, d_model=256, d_v=128, data='exchange', data_path='exchange_rate.csv', dec_in=8, decoder='FC', dropout=0.05, embed_type='CustomEmbedding', enc_in=8, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=1e-05, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=192, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 6047232
train 5024
test 1326
[ Epoch 1 ]
  - (Training) MSE:  1.04760elapse: 0.055 min
(1326, 192, 8)
test shape:(1326, 192, 8)
Epoch 0, mse:1.9273912906646729, mae:1.1616084575653076, rmse:1.3883051872253418, mape:3.081984519958496, mspe:2500.6796875
[ Epoch 2 ]
  - (Training) MSE:  0.61894elapse: 0.056 min
(1326, 192, 8)
test shape:(1326, 192, 8)
Epoch 1, mse:1.8468843698501587, mae:1.140718698501587, rmse:1.3590012788772583, mape:3.1154417991638184, mspe:2566.1083984375
[ Epoch 3 ]
  - (Training) MSE:  0.59776elapse: 0.055 min
(1326, 192, 8)
test shape:(1326, 192, 8)
Epoch 2, mse:1.8386794328689575, mae:1.138408899307251, rmse:1.355979084968567, mape:3.1182658672332764, mspe:2571.97216796875
[ Epoch 4 ]
  - (Training) MSE:  0.59522elapse: 0.054 min
(1326, 192, 8)
test shape:(1326, 192, 8)
Epoch 3, mse:1.8379342555999756, mae:1.1380460262298584, rmse:1.3557043075561523, mape:3.122704267501831, mspe:2582.71240234375
[ Epoch 5 ]
  - (Training) MSE:  0.59509elapse: 0.053 min
(1326, 192, 8)
test shape:(1326, 192, 8)
Epoch 4, mse:1.8345576524734497, mae:1.138612151145935, rmse:1.3544584512710571, mape:3.21724534034729, mspe:2758.229736328125
Iteration best metrics: [1.8345576524734497, 1.138612151145935, 1.3544584512710571, 3.21724534034729, 2758.229736328125]
Average Metrics: [1.83455765e+00 1.13861215e+00 1.35445845e+00 3.21724534e+00
 2.75822974e+03]
