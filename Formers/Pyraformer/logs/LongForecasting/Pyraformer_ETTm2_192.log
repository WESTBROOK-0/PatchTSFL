[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=16, covariate_size=4, d_bottleneck=64, d_inner_hid=512, d_k=64, d_model=256, d_v=64, data='ETTm2', data_path='ETTm2.csv', dec_in=7, decoder='FC', dropout=0.2, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=192, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 4096128
train 34273
test 11329
[ Epoch 1 ]
  - (Training) MSE:  0.32365elapse: 0.743 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 0, mse:0.7990632057189941, mae:0.7064110040664673, rmse:0.893903374671936, mape:6.619233131408691, mspe:6566.78662109375
[ Epoch 2 ]
  - (Training) MSE:  0.22464elapse: 0.747 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 1, mse:0.7022863030433655, mae:0.6647138595581055, rmse:0.8380252122879028, mape:5.378992557525635, mspe:4083.63671875
[ Epoch 3 ]
  - (Training) MSE:  0.21812elapse: 0.748 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 2, mse:0.7859494090080261, mae:0.7132902145385742, rmse:0.8865378499031067, mape:6.14675760269165, mspe:5484.53271484375
[ Epoch 4 ]
  - (Training) MSE:  0.21686elapse: 0.745 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 3, mse:0.7846418023109436, mae:0.7123737335205078, rmse:0.8858000636100769, mape:6.152083396911621, mspe:5477.8935546875
[ Epoch 5 ]
  - (Training) MSE:  0.21677elapse: 0.736 min
(11329, 192, 7)
test shape:(11329, 192, 7)
Epoch 4, mse:0.7822659015655518, mae:0.7106872797012329, rmse:0.8844579458236694, mape:6.163347244262695, mspe:5522.0654296875
Iteration best metrics: [0.7022863030433655, 0.6647138595581055, 0.8380252122879028, 5.378992557525635, 4083.63671875]
Average Metrics: [7.02286303e-01 6.64713860e-01 8.38025212e-01 5.37899256e+00
 4.08363672e+03]
