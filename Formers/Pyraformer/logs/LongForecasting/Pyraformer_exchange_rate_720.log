[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=128, d_inner_hid=512, d_k=128, d_model=256, d_v=128, data='exchange', data_path='exchange_rate.csv', dec_in=8, decoder='FC', dropout=0.05, embed_type='CustomEmbedding', enc_in=8, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=1e-05, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=720, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 10372608
train 4496
test 798
[ Epoch 1 ]
  - (Training) MSE:  0.88000elapse: 0.051 min
(798, 720, 8)
test shape:(798, 720, 8)
Epoch 0, mse:2.186072826385498, mae:1.2312581539154053, rmse:1.4785374402999878, mape:3.0591039657592773, mspe:2170.12841796875
[ Epoch 2 ]
  - (Training) MSE:  0.62438elapse: 0.055 min
(798, 720, 8)
test shape:(798, 720, 8)
Epoch 1, mse:2.1255743503570557, mae:1.2190227508544922, rmse:1.4579349756240845, mape:3.1214182376861572, mspe:2247.016357421875
[ Epoch 3 ]
  - (Training) MSE:  0.61025elapse: 0.056 min
(798, 720, 8)
test shape:(798, 720, 8)
Epoch 2, mse:2.111694097518921, mae:1.2155711650848389, rmse:1.4531669616699219, mape:3.161783456802368, mspe:2315.9248046875
[ Epoch 4 ]
  - (Training) MSE:  0.60841elapse: 0.053 min
(798, 720, 8)
test shape:(798, 720, 8)
Epoch 3, mse:2.1182546615600586, mae:1.2174365520477295, rmse:1.4554225206375122, mape:3.1302852630615234, mspe:2258.618408203125
[ Epoch 5 ]
  - (Training) MSE:  0.60735elapse: 0.050 min
(798, 720, 8)
test shape:(798, 720, 8)
Epoch 4, mse:2.1049036979675293, mae:1.2136950492858887, rmse:1.4508286714553833, mape:3.188385486602783, mspe:2364.068603515625
Iteration best metrics: [2.1049036979675293, 1.2136950492858887, 1.4508286714553833, 3.188385486602783, 2364.068603515625]
Average Metrics: [2.10490370e+00 1.21369505e+00 1.45082867e+00 3.18838549e+00
 2.36406860e+03]
