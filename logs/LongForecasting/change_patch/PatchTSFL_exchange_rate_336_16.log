Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=256, d_layers=1, d_model=128, data='custom', data_path='exchange_rate.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.2, e_layers=3, embed='timeF', embed_type=0, enc_in=8, factor=1, fc_dropout=0.2, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', mode_select='random', model='PatchTSFL', model_id='exchange_rate_336_16', modes=64, moving_avg=25, n_heads=8, num_workers=0, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=96, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=16, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
fourier enhanced block used!
modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>>>>>>start training : exchange_rate_336_16_PatchTSFL_custom_ftM_sl336_ll48_pl96_dm128_nh8_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4880
val 665
test 1422
Epoch: 1 cost time: 1.4536242485046387
Epoch: 1, Steps: 38 | Train Loss: 0.4356644 Vali Loss: 0.3680853 Test Loss: 0.3288678
Validation loss decreased (inf --> 0.368085).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.3956010341644287
Epoch: 2, Steps: 38 | Train Loss: 0.3879552 Vali Loss: 0.2490006 Test Loss: 0.2012070
Validation loss decreased (0.368085 --> 0.249001).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 1.4384946823120117
Epoch: 3, Steps: 38 | Train Loss: 0.2202979 Vali Loss: 0.2254393 Test Loss: 0.1448889
Validation loss decreased (0.249001 --> 0.225439).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 1.4108469486236572
Epoch: 4, Steps: 38 | Train Loss: 0.1565877 Vali Loss: 0.2539381 Test Loss: 0.1612349
EarlyStopping counter: 1 out of 20
Updating learning rate to 9e-05
Epoch: 5 cost time: 1.4097442626953125
Epoch: 5, Steps: 38 | Train Loss: 0.1422428 Vali Loss: 0.1886751 Test Loss: 0.1212831
Validation loss decreased (0.225439 --> 0.188675).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 1.4259440898895264
Epoch: 6, Steps: 38 | Train Loss: 0.1343482 Vali Loss: 0.1660743 Test Loss: 0.1079722
Validation loss decreased (0.188675 --> 0.166074).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 1.4064974784851074
Epoch: 7, Steps: 38 | Train Loss: 0.1284576 Vali Loss: 0.1537022 Test Loss: 0.1007196
Validation loss decreased (0.166074 --> 0.153702).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 1.4171390533447266
Epoch: 8, Steps: 38 | Train Loss: 0.1261664 Vali Loss: 0.1482162 Test Loss: 0.0999476
Validation loss decreased (0.153702 --> 0.148216).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 1.4060029983520508
Epoch: 9, Steps: 38 | Train Loss: 0.1240482 Vali Loss: 0.1487295 Test Loss: 0.1000834
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 1.411802053451538
Epoch: 10, Steps: 38 | Train Loss: 0.1226016 Vali Loss: 0.1476529 Test Loss: 0.0992772
Validation loss decreased (0.148216 --> 0.147653).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 1.4283974170684814
Epoch: 11, Steps: 38 | Train Loss: 0.1217555 Vali Loss: 0.1488742 Test Loss: 0.0993607
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 1.4351129531860352
Epoch: 12, Steps: 38 | Train Loss: 0.1207704 Vali Loss: 0.1470975 Test Loss: 0.0985000
Validation loss decreased (0.147653 --> 0.147097).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 1.4069361686706543
Epoch: 13, Steps: 38 | Train Loss: 0.1199077 Vali Loss: 0.1486351 Test Loss: 0.0984854
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 1.4177405834197998
Epoch: 14, Steps: 38 | Train Loss: 0.1196141 Vali Loss: 0.1449937 Test Loss: 0.0987917
Validation loss decreased (0.147097 --> 0.144994).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 1.4127655029296875
Epoch: 15, Steps: 38 | Train Loss: 0.1189269 Vali Loss: 0.1443007 Test Loss: 0.0981614
Validation loss decreased (0.144994 --> 0.144301).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 1.4155550003051758
Epoch: 16, Steps: 38 | Train Loss: 0.1183610 Vali Loss: 0.1468229 Test Loss: 0.0978596
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 1.4140913486480713
Epoch: 17, Steps: 38 | Train Loss: 0.1176286 Vali Loss: 0.1458583 Test Loss: 0.0973335
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 1.4208729267120361
Epoch: 18, Steps: 38 | Train Loss: 0.1172633 Vali Loss: 0.1456070 Test Loss: 0.0974212
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 1.4061064720153809
Epoch: 19, Steps: 38 | Train Loss: 0.1174273 Vali Loss: 0.1443706 Test Loss: 0.0972960
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 1.3994262218475342
Epoch: 20, Steps: 38 | Train Loss: 0.1168730 Vali Loss: 0.1464895 Test Loss: 0.0968082
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 1.3950982093811035
Epoch: 21, Steps: 38 | Train Loss: 0.1168217 Vali Loss: 0.1463583 Test Loss: 0.0971380
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 1.3983335494995117
Epoch: 22, Steps: 38 | Train Loss: 0.1164998 Vali Loss: 0.1473189 Test Loss: 0.0965757
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 1.4039607048034668
Epoch: 23, Steps: 38 | Train Loss: 0.1161717 Vali Loss: 0.1461831 Test Loss: 0.0968356
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 1.4025297164916992
Epoch: 24, Steps: 38 | Train Loss: 0.1160935 Vali Loss: 0.1455629 Test Loss: 0.0968026
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 1.4323649406433105
Epoch: 25, Steps: 38 | Train Loss: 0.1159022 Vali Loss: 0.1474467 Test Loss: 0.0968892
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 1.407874345779419
Epoch: 26, Steps: 38 | Train Loss: 0.1157701 Vali Loss: 0.1495913 Test Loss: 0.0963892
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 1.403855562210083
Epoch: 27, Steps: 38 | Train Loss: 0.1155410 Vali Loss: 0.1458741 Test Loss: 0.0966207
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 1.4066424369812012
Epoch: 28, Steps: 38 | Train Loss: 0.1154518 Vali Loss: 0.1466141 Test Loss: 0.0963997
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 1.4135937690734863
Epoch: 29, Steps: 38 | Train Loss: 0.1155277 Vali Loss: 0.1467426 Test Loss: 0.0965912
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 1.4091508388519287
Epoch: 30, Steps: 38 | Train Loss: 0.1153044 Vali Loss: 0.1463324 Test Loss: 0.0963410
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 1.4006171226501465
Epoch: 31, Steps: 38 | Train Loss: 0.1150997 Vali Loss: 0.1486858 Test Loss: 0.0964463
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 1.4098451137542725
Epoch: 32, Steps: 38 | Train Loss: 0.1149219 Vali Loss: 0.1482004 Test Loss: 0.0962001
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 1.4097318649291992
Epoch: 33, Steps: 38 | Train Loss: 0.1151070 Vali Loss: 0.1487626 Test Loss: 0.0963531
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 1.4065282344818115
Epoch: 34, Steps: 38 | Train Loss: 0.1149220 Vali Loss: 0.1473632 Test Loss: 0.0964011
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 1.388695240020752
Epoch: 35, Steps: 38 | Train Loss: 0.1150363 Vali Loss: 0.1475601 Test Loss: 0.0961863
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : exchange_rate_336_16_PatchTSFL_custom_ftM_sl336_ll48_pl96_dm128_nh8_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1422
mse:0.09816142916679382, mae:0.22191467881202698, rse:0.23862579464912415
