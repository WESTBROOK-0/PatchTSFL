Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='Autoformer', model_id='ili_36_24', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=24, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ili_36_24_Autoformer_custom_ftM_sl36_ll18_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 617
val 74
test 170
Epoch: 1 cost time: 2.398930072784424
Epoch: 1, Steps: 4 | Train Loss: 1.5228059 Vali Loss: nan Test Loss: 5.5424571
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.2221288681030273
Epoch: 2, Steps: 4 | Train Loss: 1.5148648 Vali Loss: nan Test Loss: 5.0608053
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.361321449279785
Epoch: 3, Steps: 4 | Train Loss: 1.1928513 Vali Loss: nan Test Loss: 4.6467547
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.336077928543091
Epoch: 4, Steps: 4 | Train Loss: 1.0787267 Vali Loss: nan Test Loss: 4.5046911
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.270017147064209
Epoch: 5, Steps: 4 | Train Loss: 0.9770424 Vali Loss: nan Test Loss: 4.3078055
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.296334743499756
Epoch: 6, Steps: 4 | Train Loss: 0.9158043 Vali Loss: nan Test Loss: 4.1594062
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.315678358078003
Epoch: 7, Steps: 4 | Train Loss: 0.8544938 Vali Loss: nan Test Loss: 4.0203924
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.2609102725982666
Epoch: 8, Steps: 4 | Train Loss: 0.7330212 Vali Loss: nan Test Loss: 3.9309151
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.335278272628784
Epoch: 9, Steps: 4 | Train Loss: 0.7485349 Vali Loss: nan Test Loss: 3.8371546
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.4040324687957764
Epoch: 10, Steps: 4 | Train Loss: 0.6885691 Vali Loss: nan Test Loss: 3.7458329
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.366349935531616
Epoch: 11, Steps: 4 | Train Loss: 0.6472061 Vali Loss: nan Test Loss: 3.6663105
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.4401967525482178
Epoch: 12, Steps: 4 | Train Loss: 0.6559119 Vali Loss: nan Test Loss: 3.6004915
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.3568243980407715
Epoch: 13, Steps: 4 | Train Loss: 0.6128565 Vali Loss: nan Test Loss: 3.5485506
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.3432834148406982
Epoch: 14, Steps: 4 | Train Loss: 0.5830563 Vali Loss: nan Test Loss: 3.4924331
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.5204362869262695
Epoch: 15, Steps: 4 | Train Loss: 0.5671441 Vali Loss: nan Test Loss: 3.4456310
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.3060302734375
Epoch: 16, Steps: 4 | Train Loss: 0.5533231 Vali Loss: nan Test Loss: 3.4127843
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.349841356277466
Epoch: 17, Steps: 4 | Train Loss: 0.5622942 Vali Loss: nan Test Loss: 3.3821294
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.4583637714385986
Epoch: 18, Steps: 4 | Train Loss: 0.5553892 Vali Loss: nan Test Loss: 3.3607073
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.4000930786132812
Epoch: 19, Steps: 4 | Train Loss: 0.5312532 Vali Loss: nan Test Loss: 3.3478816
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.248741626739502
Epoch: 20, Steps: 4 | Train Loss: 0.5255626 Vali Loss: nan Test Loss: 3.3391109
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.293968915939331
Epoch: 21, Steps: 4 | Train Loss: 0.5306588 Vali Loss: nan Test Loss: 3.3315632
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.2927122116088867
Epoch: 22, Steps: 4 | Train Loss: 0.5056955 Vali Loss: nan Test Loss: 3.3197618
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.174764633178711
Epoch: 23, Steps: 4 | Train Loss: 0.5016376 Vali Loss: nan Test Loss: 3.3118293
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.522962808609009
Epoch: 24, Steps: 4 | Train Loss: 0.5139971 Vali Loss: nan Test Loss: 3.3041682
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.3527050018310547
Epoch: 25, Steps: 4 | Train Loss: 0.5066684 Vali Loss: nan Test Loss: 3.2928646
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.395970106124878
Epoch: 26, Steps: 4 | Train Loss: 0.5089009 Vali Loss: nan Test Loss: 3.2810488
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.283355951309204
Epoch: 27, Steps: 4 | Train Loss: 0.5110316 Vali Loss: nan Test Loss: 3.2739930
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.106504440307617
Epoch: 28, Steps: 4 | Train Loss: 0.4827030 Vali Loss: nan Test Loss: 3.2706749
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.494580030441284
Epoch: 29, Steps: 4 | Train Loss: 0.5035602 Vali Loss: nan Test Loss: 3.2651362
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.1633825302124023
Epoch: 30, Steps: 4 | Train Loss: 0.4826892 Vali Loss: nan Test Loss: 3.2576149
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.1697769165039062
Epoch: 31, Steps: 4 | Train Loss: 0.4770534 Vali Loss: nan Test Loss: 3.2530148
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.429530143737793
Epoch: 32, Steps: 4 | Train Loss: 0.4843158 Vali Loss: nan Test Loss: 3.2476523
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.3465030193328857
Epoch: 33, Steps: 4 | Train Loss: 0.4883126 Vali Loss: nan Test Loss: 3.2448847
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.286712169647217
Epoch: 34, Steps: 4 | Train Loss: 0.4908944 Vali Loss: nan Test Loss: 3.2447495
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.3716495037078857
Epoch: 35, Steps: 4 | Train Loss: 0.4968766 Vali Loss: nan Test Loss: 3.2440228
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.321955919265747
Epoch: 36, Steps: 4 | Train Loss: 0.4809639 Vali Loss: nan Test Loss: 3.2420330
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.206061840057373
Epoch: 37, Steps: 4 | Train Loss: 0.5116332 Vali Loss: nan Test Loss: 3.2416062
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.2732646465301514
Epoch: 38, Steps: 4 | Train Loss: 0.4831813 Vali Loss: nan Test Loss: 3.2405519
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.3434934616088867
Epoch: 39, Steps: 4 | Train Loss: 0.4964161 Vali Loss: nan Test Loss: 3.2418685
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.3940088748931885
Epoch: 40, Steps: 4 | Train Loss: 0.4824906 Vali Loss: nan Test Loss: 3.2434444
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.378006935119629
Epoch: 41, Steps: 4 | Train Loss: 0.4602608 Vali Loss: nan Test Loss: 3.2438285
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.375296115875244
Epoch: 42, Steps: 4 | Train Loss: 0.4890976 Vali Loss: nan Test Loss: 3.2432201
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 2.2909762859344482
Epoch: 43, Steps: 4 | Train Loss: 0.4709408 Vali Loss: nan Test Loss: 3.2433209
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 2.2602486610412598
Epoch: 44, Steps: 4 | Train Loss: 0.4867151 Vali Loss: nan Test Loss: 3.2422645
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 2.320035457611084
Epoch: 45, Steps: 4 | Train Loss: 0.4736026 Vali Loss: nan Test Loss: 3.2412200
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 2.330199956893921
Epoch: 46, Steps: 4 | Train Loss: 0.4454006 Vali Loss: nan Test Loss: 3.2411931
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.3565866947174072
Epoch: 47, Steps: 4 | Train Loss: 0.4615429 Vali Loss: nan Test Loss: 3.2394047
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 2.201347827911377
Epoch: 48, Steps: 4 | Train Loss: 0.4433447 Vali Loss: nan Test Loss: 3.2391143
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 2.2558975219726562
Epoch: 49, Steps: 4 | Train Loss: 0.4829812 Vali Loss: nan Test Loss: 3.2373526
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 2.4260497093200684
Epoch: 50, Steps: 4 | Train Loss: 0.4640939 Vali Loss: nan Test Loss: 3.2384048
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.2794909477233887
Epoch: 51, Steps: 4 | Train Loss: 0.4802957 Vali Loss: nan Test Loss: 3.2380970
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.3759751319885254
Epoch: 52, Steps: 4 | Train Loss: 0.4723977 Vali Loss: nan Test Loss: 3.2379680
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.0770857334136963
Epoch: 53, Steps: 4 | Train Loss: 0.4792397 Vali Loss: nan Test Loss: 3.2396870
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 2.365137815475464
Epoch: 54, Steps: 4 | Train Loss: 0.4758805 Vali Loss: nan Test Loss: 3.2398319
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 2.3321585655212402
Epoch: 55, Steps: 4 | Train Loss: 0.4816938 Vali Loss: nan Test Loss: 3.2396774
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.2936203479766846
Epoch: 56, Steps: 4 | Train Loss: 0.4690941 Vali Loss: nan Test Loss: 3.2399364
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 2.2705020904541016
Epoch: 57, Steps: 4 | Train Loss: 0.4686135 Vali Loss: nan Test Loss: 3.2398105
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 2.2015180587768555
Epoch: 58, Steps: 4 | Train Loss: 0.4678173 Vali Loss: nan Test Loss: 3.2410536
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 2.3078055381774902
Epoch: 59, Steps: 4 | Train Loss: 0.4804686 Vali Loss: nan Test Loss: 3.2409551
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 2.3622586727142334
Epoch: 60, Steps: 4 | Train Loss: 0.4735406 Vali Loss: nan Test Loss: 3.2404659
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 2.5377533435821533
Epoch: 61, Steps: 4 | Train Loss: 0.4893333 Vali Loss: nan Test Loss: 3.2404313
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 2.3945157527923584
Epoch: 62, Steps: 4 | Train Loss: 0.4655081 Vali Loss: nan Test Loss: 3.2404077
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 2.201122522354126
Epoch: 63, Steps: 4 | Train Loss: 0.4724790 Vali Loss: nan Test Loss: 3.2401261
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 2.3422346115112305
Epoch: 64, Steps: 4 | Train Loss: 0.4830506 Vali Loss: nan Test Loss: 3.2400484
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.3524324893951416
Epoch: 65, Steps: 4 | Train Loss: 0.4672890 Vali Loss: nan Test Loss: 3.2417512
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 2.4356157779693604
Epoch: 66, Steps: 4 | Train Loss: 0.4528863 Vali Loss: nan Test Loss: 3.2416949
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.3232781887054443
Epoch: 67, Steps: 4 | Train Loss: 0.4693241 Vali Loss: nan Test Loss: 3.2416437
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 2.195094585418701
Epoch: 68, Steps: 4 | Train Loss: 0.4753025 Vali Loss: nan Test Loss: 3.2418783
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 2.250271797180176
Epoch: 69, Steps: 4 | Train Loss: 0.4809624 Vali Loss: nan Test Loss: 3.2418442
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.034946918487549
Epoch: 70, Steps: 4 | Train Loss: 0.4614794 Vali Loss: nan Test Loss: 3.2418201
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 2.1687071323394775
Epoch: 71, Steps: 4 | Train Loss: 0.4866387 Vali Loss: nan Test Loss: 3.2417984
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.3580474853515625
Epoch: 72, Steps: 4 | Train Loss: 0.4605802 Vali Loss: nan Test Loss: 3.2418115
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 2.2350614070892334
Epoch: 73, Steps: 4 | Train Loss: 0.4820730 Vali Loss: nan Test Loss: 3.2418218
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.1903586387634277
Epoch: 74, Steps: 4 | Train Loss: 0.4705775 Vali Loss: nan Test Loss: 3.2418435
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 2.3238613605499268
Epoch: 75, Steps: 4 | Train Loss: 0.4621662 Vali Loss: nan Test Loss: 3.2416244
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 2.3540542125701904
Epoch: 76, Steps: 4 | Train Loss: 0.4642808 Vali Loss: nan Test Loss: 3.2416201
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 2.246929883956909
Epoch: 77, Steps: 4 | Train Loss: 0.4871830 Vali Loss: nan Test Loss: 3.2416167
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 2.364391565322876
Epoch: 78, Steps: 4 | Train Loss: 0.4830141 Vali Loss: nan Test Loss: 3.2415965
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 2.1534996032714844
Epoch: 79, Steps: 4 | Train Loss: 0.4373517 Vali Loss: nan Test Loss: 3.2415841
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.1670093536376953
Epoch: 80, Steps: 4 | Train Loss: 0.4655774 Vali Loss: nan Test Loss: 3.2415745
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 2.3514997959136963
Epoch: 81, Steps: 4 | Train Loss: 0.4797721 Vali Loss: nan Test Loss: 3.2415681
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.2766411304473877
Epoch: 82, Steps: 4 | Train Loss: 0.4830147 Vali Loss: nan Test Loss: 3.2415488
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 2.103518009185791
Epoch: 83, Steps: 4 | Train Loss: 0.4765714 Vali Loss: nan Test Loss: 3.2415378
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 2.2578134536743164
Epoch: 84, Steps: 4 | Train Loss: 0.4697478 Vali Loss: nan Test Loss: 3.2415264
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 2.3651790618896484
Epoch: 85, Steps: 4 | Train Loss: 0.4418224 Vali Loss: nan Test Loss: 3.2415121
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 2.598587989807129
Epoch: 86, Steps: 4 | Train Loss: 0.4794689 Vali Loss: nan Test Loss: 3.2415066
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.4932808876037598
Epoch: 87, Steps: 4 | Train Loss: 0.4774248 Vali Loss: nan Test Loss: 3.2414982
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 2.250084638595581
Epoch: 88, Steps: 4 | Train Loss: 0.4631963 Vali Loss: nan Test Loss: 3.2414911
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.2676548957824707
Epoch: 89, Steps: 4 | Train Loss: 0.4707230 Vali Loss: nan Test Loss: 3.2414830
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 2.4896278381347656
Epoch: 90, Steps: 4 | Train Loss: 0.4826257 Vali Loss: nan Test Loss: 3.2414834
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 2.29386568069458
Epoch: 91, Steps: 4 | Train Loss: 0.4596706 Vali Loss: nan Test Loss: 3.2414813
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 2.357198476791382
Epoch: 92, Steps: 4 | Train Loss: 0.4703959 Vali Loss: nan Test Loss: 3.2414765
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.4456512928009033
Epoch: 93, Steps: 4 | Train Loss: 0.4726092 Vali Loss: nan Test Loss: 3.2414715
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 2.2686097621917725
Epoch: 94, Steps: 4 | Train Loss: 0.4926262 Vali Loss: nan Test Loss: 3.2414663
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.0869674682617188
Epoch: 95, Steps: 4 | Train Loss: 0.4611224 Vali Loss: nan Test Loss: 3.2414689
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 2.377974510192871
Epoch: 96, Steps: 4 | Train Loss: 0.4438249 Vali Loss: nan Test Loss: 3.2414682
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.353365182876587
Epoch: 97, Steps: 4 | Train Loss: 0.4674359 Vali Loss: nan Test Loss: 3.2414684
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 2.47214937210083
Epoch: 98, Steps: 4 | Train Loss: 0.4809984 Vali Loss: nan Test Loss: 3.2414646
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 2.271832227706909
Epoch: 99, Steps: 4 | Train Loss: 0.4638471 Vali Loss: nan Test Loss: 3.2414703
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 2.40519118309021
Epoch: 100, Steps: 4 | Train Loss: 0.4587132 Vali Loss: nan Test Loss: 3.2414675
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : ili_36_24_Autoformer_custom_ftM_sl36_ll18_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 170
mse:3.2414674758911133, mae:1.1900973320007324, rse:0.8777431845664978
