Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='Informer', model_id='ili_36_24', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=24, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ili_36_24_Informer_custom_ftM_sl36_ll18_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 617
val 74
test 170
Epoch: 1 cost time: 2.0941483974456787
Epoch: 1, Steps: 4 | Train Loss: 1.3673579 Vali Loss: nan Test Loss: 7.6629496
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.0983333587646484
Epoch: 2, Steps: 4 | Train Loss: 1.0176633 Vali Loss: nan Test Loss: 5.1501451
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.2404003143310547
Epoch: 3, Steps: 4 | Train Loss: 0.8651917 Vali Loss: nan Test Loss: 4.6702061
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.1758596897125244
Epoch: 4, Steps: 4 | Train Loss: 0.7245829 Vali Loss: nan Test Loss: 5.0378480
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.0252127647399902
Epoch: 5, Steps: 4 | Train Loss: 0.6590587 Vali Loss: nan Test Loss: 5.0712829
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.0891506671905518
Epoch: 6, Steps: 4 | Train Loss: 0.6188065 Vali Loss: nan Test Loss: 4.8619475
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.206709861755371
Epoch: 7, Steps: 4 | Train Loss: 0.5598617 Vali Loss: nan Test Loss: 5.0688162
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.1561050415039062
Epoch: 8, Steps: 4 | Train Loss: 0.5141603 Vali Loss: nan Test Loss: 5.3891726
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.195093870162964
Epoch: 9, Steps: 4 | Train Loss: 0.4433980 Vali Loss: nan Test Loss: 5.4353199
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.086221694946289
Epoch: 10, Steps: 4 | Train Loss: 0.4295176 Vali Loss: nan Test Loss: 5.6405067
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.252608060836792
Epoch: 11, Steps: 4 | Train Loss: 0.4039632 Vali Loss: nan Test Loss: 5.7125297
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.083787202835083
Epoch: 12, Steps: 4 | Train Loss: 0.4038369 Vali Loss: nan Test Loss: 5.5702124
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.209432363510132
Epoch: 13, Steps: 4 | Train Loss: 0.3960481 Vali Loss: nan Test Loss: 5.6710510
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.0766263008117676
Epoch: 14, Steps: 4 | Train Loss: 0.3739978 Vali Loss: nan Test Loss: 5.5499430
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.127185583114624
Epoch: 15, Steps: 4 | Train Loss: 0.3525036 Vali Loss: nan Test Loss: 5.3645058
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.0755956172943115
Epoch: 16, Steps: 4 | Train Loss: 0.3585960 Vali Loss: nan Test Loss: 5.4923816
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.091801404953003
Epoch: 17, Steps: 4 | Train Loss: 0.3467260 Vali Loss: nan Test Loss: 5.4763627
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.1026968955993652
Epoch: 18, Steps: 4 | Train Loss: 0.3392965 Vali Loss: nan Test Loss: 5.3101959
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.1545190811157227
Epoch: 19, Steps: 4 | Train Loss: 0.3461926 Vali Loss: nan Test Loss: 5.2525778
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 1.8625645637512207
Epoch: 20, Steps: 4 | Train Loss: 0.3567892 Vali Loss: nan Test Loss: 5.3457360
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.2069315910339355
Epoch: 21, Steps: 4 | Train Loss: 0.3430857 Vali Loss: nan Test Loss: 5.3805161
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.1974780559539795
Epoch: 22, Steps: 4 | Train Loss: 0.3289200 Vali Loss: nan Test Loss: 5.3327003
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.011082887649536
Epoch: 23, Steps: 4 | Train Loss: 0.3296789 Vali Loss: nan Test Loss: 5.3221169
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.042059898376465
Epoch: 24, Steps: 4 | Train Loss: 0.3154202 Vali Loss: nan Test Loss: 5.2988043
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.15639591217041
Epoch: 25, Steps: 4 | Train Loss: 0.3251731 Vali Loss: nan Test Loss: 5.2936172
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.25050687789917
Epoch: 26, Steps: 4 | Train Loss: 0.3187371 Vali Loss: nan Test Loss: 5.3283744
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.152348756790161
Epoch: 27, Steps: 4 | Train Loss: 0.3062760 Vali Loss: nan Test Loss: 5.3081689
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.2620959281921387
Epoch: 28, Steps: 4 | Train Loss: 0.3163505 Vali Loss: nan Test Loss: 5.2565145
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.0629639625549316
Epoch: 29, Steps: 4 | Train Loss: 0.2884780 Vali Loss: nan Test Loss: 5.2130027
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.2973718643188477
Epoch: 30, Steps: 4 | Train Loss: 0.3030214 Vali Loss: nan Test Loss: 5.1948552
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.1688356399536133
Epoch: 31, Steps: 4 | Train Loss: 0.3115452 Vali Loss: nan Test Loss: 5.2591224
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.208174705505371
Epoch: 32, Steps: 4 | Train Loss: 0.2962042 Vali Loss: nan Test Loss: 5.2651587
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.223982334136963
Epoch: 33, Steps: 4 | Train Loss: 0.3063689 Vali Loss: nan Test Loss: 5.3120961
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.0935025215148926
Epoch: 34, Steps: 4 | Train Loss: 0.2949486 Vali Loss: nan Test Loss: 5.3219094
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.274880886077881
Epoch: 35, Steps: 4 | Train Loss: 0.3005940 Vali Loss: nan Test Loss: 5.2417769
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.3727564811706543
Epoch: 36, Steps: 4 | Train Loss: 0.3073966 Vali Loss: nan Test Loss: 5.2236686
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.2403976917266846
Epoch: 37, Steps: 4 | Train Loss: 0.2943859 Vali Loss: nan Test Loss: 5.2096891
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.280632734298706
Epoch: 38, Steps: 4 | Train Loss: 0.2948488 Vali Loss: nan Test Loss: 5.1926675
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.1265904903411865
Epoch: 39, Steps: 4 | Train Loss: 0.3021040 Vali Loss: nan Test Loss: 5.2181730
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.157033920288086
Epoch: 40, Steps: 4 | Train Loss: 0.2964652 Vali Loss: nan Test Loss: 5.2310052
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.1852214336395264
Epoch: 41, Steps: 4 | Train Loss: 0.2861488 Vali Loss: nan Test Loss: 5.2321434
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.251927375793457
Epoch: 42, Steps: 4 | Train Loss: 0.3021339 Vali Loss: nan Test Loss: 5.2522798
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 2.168330669403076
Epoch: 43, Steps: 4 | Train Loss: 0.2967322 Vali Loss: nan Test Loss: 5.2341099
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 2.3152236938476562
Epoch: 44, Steps: 4 | Train Loss: 0.3040860 Vali Loss: nan Test Loss: 5.2364583
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 1.9904334545135498
Epoch: 45, Steps: 4 | Train Loss: 0.2896049 Vali Loss: nan Test Loss: 5.2526298
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 2.3234777450561523
Epoch: 46, Steps: 4 | Train Loss: 0.2981794 Vali Loss: nan Test Loss: 5.2249808
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.1784493923187256
Epoch: 47, Steps: 4 | Train Loss: 0.3001913 Vali Loss: nan Test Loss: 5.2211456
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 2.3542988300323486
Epoch: 48, Steps: 4 | Train Loss: 0.2934794 Vali Loss: nan Test Loss: 5.2307606
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 2.1721303462982178
Epoch: 49, Steps: 4 | Train Loss: 0.3063257 Vali Loss: nan Test Loss: 5.2391329
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 1.9618239402770996
Epoch: 50, Steps: 4 | Train Loss: 0.3020103 Vali Loss: nan Test Loss: 5.2320657
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.4153592586517334
Epoch: 51, Steps: 4 | Train Loss: 0.2963044 Vali Loss: nan Test Loss: 5.2118363
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.1833715438842773
Epoch: 52, Steps: 4 | Train Loss: 0.3092624 Vali Loss: nan Test Loss: 5.2033148
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.3376412391662598
Epoch: 53, Steps: 4 | Train Loss: 0.2976740 Vali Loss: nan Test Loss: 5.2087960
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 2.1151037216186523
Epoch: 54, Steps: 4 | Train Loss: 0.3012038 Vali Loss: nan Test Loss: 5.1827340
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 2.285175085067749
Epoch: 55, Steps: 4 | Train Loss: 0.2952548 Vali Loss: nan Test Loss: 5.2008600
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.243722915649414
Epoch: 56, Steps: 4 | Train Loss: 0.2919365 Vali Loss: nan Test Loss: 5.2102404
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 2.210960865020752
Epoch: 57, Steps: 4 | Train Loss: 0.2960304 Vali Loss: nan Test Loss: 5.1947951
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 2.0695197582244873
Epoch: 58, Steps: 4 | Train Loss: 0.2953921 Vali Loss: nan Test Loss: 5.1831031
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 2.2977027893066406
Epoch: 59, Steps: 4 | Train Loss: 0.2972858 Vali Loss: nan Test Loss: 5.1994715
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 2.048146963119507
Epoch: 60, Steps: 4 | Train Loss: 0.2952841 Vali Loss: nan Test Loss: 5.1937218
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 2.1074416637420654
Epoch: 61, Steps: 4 | Train Loss: 0.2970046 Vali Loss: nan Test Loss: 5.2005081
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 2.126960515975952
Epoch: 62, Steps: 4 | Train Loss: 0.3022780 Vali Loss: nan Test Loss: 5.2054453
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 2.0907979011535645
Epoch: 63, Steps: 4 | Train Loss: 0.2932920 Vali Loss: nan Test Loss: 5.2044840
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 2.0224366188049316
Epoch: 64, Steps: 4 | Train Loss: 0.2947197 Vali Loss: nan Test Loss: 5.2240562
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.1990182399749756
Epoch: 65, Steps: 4 | Train Loss: 0.3030127 Vali Loss: nan Test Loss: 5.1857157
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 2.214138984680176
Epoch: 66, Steps: 4 | Train Loss: 0.2810435 Vali Loss: nan Test Loss: 5.1730962
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.228675127029419
Epoch: 67, Steps: 4 | Train Loss: 0.2905429 Vali Loss: nan Test Loss: 5.1915898
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 2.0729358196258545
Epoch: 68, Steps: 4 | Train Loss: 0.2926204 Vali Loss: nan Test Loss: 5.2161708
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 2.3969762325286865
Epoch: 69, Steps: 4 | Train Loss: 0.2812033 Vali Loss: nan Test Loss: 5.2039161
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.3319990634918213
Epoch: 70, Steps: 4 | Train Loss: 0.2840632 Vali Loss: nan Test Loss: 5.2012215
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 2.143170118331909
Epoch: 71, Steps: 4 | Train Loss: 0.2896326 Vali Loss: nan Test Loss: 5.1799092
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.1529901027679443
Epoch: 72, Steps: 4 | Train Loss: 0.2940669 Vali Loss: nan Test Loss: 5.2225485
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 1.9801404476165771
Epoch: 73, Steps: 4 | Train Loss: 0.3051808 Vali Loss: nan Test Loss: 5.2064261
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.149517297744751
Epoch: 74, Steps: 4 | Train Loss: 0.2848254 Vali Loss: nan Test Loss: 5.2084713
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 2.3224854469299316
Epoch: 75, Steps: 4 | Train Loss: 0.2956652 Vali Loss: nan Test Loss: 5.1968207
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 2.065671682357788
Epoch: 76, Steps: 4 | Train Loss: 0.2819712 Vali Loss: nan Test Loss: 5.2112899
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 2.30478572845459
Epoch: 77, Steps: 4 | Train Loss: 0.2825912 Vali Loss: nan Test Loss: 5.2033563
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 2.42724347114563
Epoch: 78, Steps: 4 | Train Loss: 0.3048543 Vali Loss: nan Test Loss: 5.2166796
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 2.2823920249938965
Epoch: 79, Steps: 4 | Train Loss: 0.2936459 Vali Loss: nan Test Loss: 5.2060599
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.160118579864502
Epoch: 80, Steps: 4 | Train Loss: 0.2931698 Vali Loss: nan Test Loss: 5.2098298
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 2.0624451637268066
Epoch: 81, Steps: 4 | Train Loss: 0.2885652 Vali Loss: nan Test Loss: 5.2047524
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.1818504333496094
Epoch: 82, Steps: 4 | Train Loss: 0.2864558 Vali Loss: nan Test Loss: 5.1940084
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 2.0737860202789307
Epoch: 83, Steps: 4 | Train Loss: 0.2880642 Vali Loss: nan Test Loss: 5.1744947
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 1.9617319107055664
Epoch: 84, Steps: 4 | Train Loss: 0.2959153 Vali Loss: nan Test Loss: 5.1947169
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 2.0451314449310303
Epoch: 85, Steps: 4 | Train Loss: 0.3025012 Vali Loss: nan Test Loss: 5.1903663
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 2.011261224746704
Epoch: 86, Steps: 4 | Train Loss: 0.2819108 Vali Loss: nan Test Loss: 5.1917648
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.241816520690918
Epoch: 87, Steps: 4 | Train Loss: 0.2893381 Vali Loss: nan Test Loss: 5.1954947
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 2.055464506149292
Epoch: 88, Steps: 4 | Train Loss: 0.3002614 Vali Loss: nan Test Loss: 5.1850228
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.3784565925598145
Epoch: 89, Steps: 4 | Train Loss: 0.2969599 Vali Loss: nan Test Loss: 5.2441053
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 2.1768195629119873
Epoch: 90, Steps: 4 | Train Loss: 0.2948926 Vali Loss: nan Test Loss: 5.1795664
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 2.1755993366241455
Epoch: 91, Steps: 4 | Train Loss: 0.2977946 Vali Loss: nan Test Loss: 5.1867180
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 2.1707582473754883
Epoch: 92, Steps: 4 | Train Loss: 0.2870251 Vali Loss: nan Test Loss: 5.1819887
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.32328724861145
Epoch: 93, Steps: 4 | Train Loss: 0.2913747 Vali Loss: nan Test Loss: 5.2070518
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 2.1372339725494385
Epoch: 94, Steps: 4 | Train Loss: 0.2903115 Vali Loss: nan Test Loss: 5.2159538
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.0165774822235107
Epoch: 95, Steps: 4 | Train Loss: 0.2806676 Vali Loss: nan Test Loss: 5.1838121
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 2.0100791454315186
Epoch: 96, Steps: 4 | Train Loss: 0.3020103 Vali Loss: nan Test Loss: 5.2167883
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.0581493377685547
Epoch: 97, Steps: 4 | Train Loss: 0.2983478 Vali Loss: nan Test Loss: 5.2146826
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 2.262326955795288
Epoch: 98, Steps: 4 | Train Loss: 0.3076877 Vali Loss: nan Test Loss: 5.2157116
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 2.346508026123047
Epoch: 99, Steps: 4 | Train Loss: 0.3031082 Vali Loss: nan Test Loss: 5.2170792
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 2.2435598373413086
Epoch: 100, Steps: 4 | Train Loss: 0.2900320 Vali Loss: nan Test Loss: 5.1874609
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : ili_36_24_Informer_custom_ftM_sl36_ll18_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 170
mse:5.21072244644165, mae:1.5468732118606567, rse:1.1128730773925781
