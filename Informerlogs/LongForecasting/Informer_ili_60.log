Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='Informer', model_id='ili_36_60', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=100, pct_start=0.3, pred_len=60, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ili_36_60_Informer_custom_ftM_sl36_ll18_pl60_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 581
val 38
test 134
Epoch: 1 cost time: 2.3573524951934814
Epoch: 1, Steps: 4 | Train Loss: 1.3252369 Vali Loss: nan Test Loss: 7.7287111
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.0432465076446533
Epoch: 2, Steps: 4 | Train Loss: 1.0233698 Vali Loss: nan Test Loss: 5.3346415
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.13360857963562
Epoch: 3, Steps: 4 | Train Loss: 0.9041795 Vali Loss: nan Test Loss: 4.7721543
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.2835543155670166
Epoch: 4, Steps: 4 | Train Loss: 0.7685771 Vali Loss: nan Test Loss: 5.1488318
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.200113534927368
Epoch: 5, Steps: 4 | Train Loss: 0.6958183 Vali Loss: nan Test Loss: 5.2342691
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.184298276901245
Epoch: 6, Steps: 4 | Train Loss: 0.6514078 Vali Loss: nan Test Loss: 4.8635893
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.213042736053467
Epoch: 7, Steps: 4 | Train Loss: 0.5931086 Vali Loss: nan Test Loss: 4.9094143
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.1820597648620605
Epoch: 8, Steps: 4 | Train Loss: 0.5508475 Vali Loss: nan Test Loss: 5.1782489
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.395052671432495
Epoch: 9, Steps: 4 | Train Loss: 0.5180490 Vali Loss: nan Test Loss: 5.1747174
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.200831174850464
Epoch: 10, Steps: 4 | Train Loss: 0.4928079 Vali Loss: nan Test Loss: 5.2275786
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.2965097427368164
Epoch: 11, Steps: 4 | Train Loss: 0.4718794 Vali Loss: nan Test Loss: 5.5037746
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.181778907775879
Epoch: 12, Steps: 4 | Train Loss: 0.4623297 Vali Loss: nan Test Loss: 5.4673386
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.0753509998321533
Epoch: 13, Steps: 4 | Train Loss: 0.4463343 Vali Loss: nan Test Loss: 5.3986955
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.26574969291687
Epoch: 14, Steps: 4 | Train Loss: 0.4481408 Vali Loss: nan Test Loss: 5.4974074
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.2567813396453857
Epoch: 15, Steps: 4 | Train Loss: 0.4259053 Vali Loss: nan Test Loss: 5.5071125
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.2900390625
Epoch: 16, Steps: 4 | Train Loss: 0.4257623 Vali Loss: nan Test Loss: 5.4758039
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.32578706741333
Epoch: 17, Steps: 4 | Train Loss: 0.4261478 Vali Loss: nan Test Loss: 5.4682026
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.2615103721618652
Epoch: 18, Steps: 4 | Train Loss: 0.4080900 Vali Loss: nan Test Loss: 5.4975924
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.228374481201172
Epoch: 19, Steps: 4 | Train Loss: 0.3964037 Vali Loss: nan Test Loss: 5.4907522
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.122824192047119
Epoch: 20, Steps: 4 | Train Loss: 0.3940381 Vali Loss: nan Test Loss: 5.4535480
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.085862398147583
Epoch: 21, Steps: 4 | Train Loss: 0.3818408 Vali Loss: nan Test Loss: 5.4361615
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.2432124614715576
Epoch: 22, Steps: 4 | Train Loss: 0.3843369 Vali Loss: nan Test Loss: 5.4311838
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.1050150394439697
Epoch: 23, Steps: 4 | Train Loss: 0.3674808 Vali Loss: nan Test Loss: 5.4062757
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.36006236076355
Epoch: 24, Steps: 4 | Train Loss: 0.3816662 Vali Loss: nan Test Loss: 5.4379907
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.172926187515259
Epoch: 25, Steps: 4 | Train Loss: 0.3818855 Vali Loss: nan Test Loss: 5.4221992
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.593424081802368
Epoch: 26, Steps: 4 | Train Loss: 0.3771563 Vali Loss: nan Test Loss: 5.3595948
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.073367118835449
Epoch: 27, Steps: 4 | Train Loss: 0.3742811 Vali Loss: nan Test Loss: 5.3616695
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.485302686691284
Epoch: 28, Steps: 4 | Train Loss: 0.3700467 Vali Loss: nan Test Loss: 5.3848391
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.60461688041687
Epoch: 29, Steps: 4 | Train Loss: 0.3586516 Vali Loss: nan Test Loss: 5.4051061
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.3405656814575195
Epoch: 30, Steps: 4 | Train Loss: 0.3617285 Vali Loss: nan Test Loss: 5.4105921
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.149991273880005
Epoch: 31, Steps: 4 | Train Loss: 0.3593454 Vali Loss: nan Test Loss: 5.4089909
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.4922683238983154
Epoch: 32, Steps: 4 | Train Loss: 0.3615771 Vali Loss: nan Test Loss: 5.4228082
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.317474842071533
Epoch: 33, Steps: 4 | Train Loss: 0.3642216 Vali Loss: nan Test Loss: 5.4138021
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.11854887008667
Epoch: 34, Steps: 4 | Train Loss: 0.3548346 Vali Loss: nan Test Loss: 5.4111304
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.56498384475708
Epoch: 35, Steps: 4 | Train Loss: 0.3579196 Vali Loss: nan Test Loss: 5.3987398
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.3215506076812744
Epoch: 36, Steps: 4 | Train Loss: 0.3527647 Vali Loss: nan Test Loss: 5.3844585
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.3134069442749023
Epoch: 37, Steps: 4 | Train Loss: 0.3580207 Vali Loss: nan Test Loss: 5.4011335
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.7095255851745605
Epoch: 38, Steps: 4 | Train Loss: 0.3469740 Vali Loss: nan Test Loss: 5.3916621
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.247532606124878
Epoch: 39, Steps: 4 | Train Loss: 0.3536988 Vali Loss: nan Test Loss: 5.3985524
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.1163816452026367
Epoch: 40, Steps: 4 | Train Loss: 0.3605364 Vali Loss: nan Test Loss: 5.3723359
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.19621205329895
Epoch: 41, Steps: 4 | Train Loss: 0.3496389 Vali Loss: nan Test Loss: 5.3825183
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.249018669128418
Epoch: 42, Steps: 4 | Train Loss: 0.3513052 Vali Loss: nan Test Loss: 5.3876390
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 2.3122410774230957
Epoch: 43, Steps: 4 | Train Loss: 0.3657578 Vali Loss: nan Test Loss: 5.3843098
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 2.068276882171631
Epoch: 44, Steps: 4 | Train Loss: 0.3539761 Vali Loss: nan Test Loss: 5.3991265
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 2.137888193130493
Epoch: 45, Steps: 4 | Train Loss: 0.3465175 Vali Loss: nan Test Loss: 5.3766489
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 2.425049304962158
Epoch: 46, Steps: 4 | Train Loss: 0.3508411 Vali Loss: nan Test Loss: 5.3827496
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.60129451751709
Epoch: 47, Steps: 4 | Train Loss: 0.3471896 Vali Loss: nan Test Loss: 5.3790936
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 2.6559174060821533
Epoch: 48, Steps: 4 | Train Loss: 0.3491588 Vali Loss: nan Test Loss: 5.3781657
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 2.613349199295044
Epoch: 49, Steps: 4 | Train Loss: 0.3566938 Vali Loss: nan Test Loss: 5.3945580
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 2.465646743774414
Epoch: 50, Steps: 4 | Train Loss: 0.3420014 Vali Loss: nan Test Loss: 5.3991642
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.5782527923583984
Epoch: 51, Steps: 4 | Train Loss: 0.3509311 Vali Loss: nan Test Loss: 5.4040246
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.5628089904785156
Epoch: 52, Steps: 4 | Train Loss: 0.3523667 Vali Loss: nan Test Loss: 5.3946061
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.3373312950134277
Epoch: 53, Steps: 4 | Train Loss: 0.3574247 Vali Loss: nan Test Loss: 5.3978095
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 2.324272632598877
Epoch: 54, Steps: 4 | Train Loss: 0.3516330 Vali Loss: nan Test Loss: 5.3936529
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 2.4587409496307373
Epoch: 55, Steps: 4 | Train Loss: 0.3561609 Vali Loss: nan Test Loss: 5.3967853
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.656585693359375
Epoch: 56, Steps: 4 | Train Loss: 0.3505092 Vali Loss: nan Test Loss: 5.4046640
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 2.16395902633667
Epoch: 57, Steps: 4 | Train Loss: 0.3600503 Vali Loss: nan Test Loss: 5.4083962
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 2.41228985786438
Epoch: 58, Steps: 4 | Train Loss: 0.3445059 Vali Loss: nan Test Loss: 5.3591113
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 2.398914337158203
Epoch: 59, Steps: 4 | Train Loss: 0.3427951 Vali Loss: nan Test Loss: 5.3864269
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 2.487668514251709
Epoch: 60, Steps: 4 | Train Loss: 0.3520970 Vali Loss: nan Test Loss: 5.3784251
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 2.2671680450439453
Epoch: 61, Steps: 4 | Train Loss: 0.3540867 Vali Loss: nan Test Loss: 5.3921571
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 2.280003786087036
Epoch: 62, Steps: 4 | Train Loss: 0.3498953 Vali Loss: nan Test Loss: 5.3880730
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 2.469578504562378
Epoch: 63, Steps: 4 | Train Loss: 0.3390986 Vali Loss: nan Test Loss: 5.3796697
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 2.335484027862549
Epoch: 64, Steps: 4 | Train Loss: 0.3447161 Vali Loss: nan Test Loss: 5.3716292
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.3873302936553955
Epoch: 65, Steps: 4 | Train Loss: 0.3445893 Vali Loss: nan Test Loss: 5.3742623
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 2.1023542881011963
Epoch: 66, Steps: 4 | Train Loss: 0.3435722 Vali Loss: nan Test Loss: 5.3724713
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.3752121925354004
Epoch: 67, Steps: 4 | Train Loss: 0.3455941 Vali Loss: nan Test Loss: 5.3671474
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 2.325037717819214
Epoch: 68, Steps: 4 | Train Loss: 0.3414665 Vali Loss: nan Test Loss: 5.3979096
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 2.361325263977051
Epoch: 69, Steps: 4 | Train Loss: 0.3488889 Vali Loss: nan Test Loss: 5.3870654
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.4437241554260254
Epoch: 70, Steps: 4 | Train Loss: 0.3487031 Vali Loss: nan Test Loss: 5.3667436
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 2.4078879356384277
Epoch: 71, Steps: 4 | Train Loss: 0.3528000 Vali Loss: nan Test Loss: 5.3772440
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.2557356357574463
Epoch: 72, Steps: 4 | Train Loss: 0.3591570 Vali Loss: nan Test Loss: 5.3919177
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 2.3112213611602783
Epoch: 73, Steps: 4 | Train Loss: 0.3462181 Vali Loss: nan Test Loss: 5.3902345
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.263688087463379
Epoch: 74, Steps: 4 | Train Loss: 0.3503547 Vali Loss: nan Test Loss: 5.3911328
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 2.170941114425659
Epoch: 75, Steps: 4 | Train Loss: 0.3526358 Vali Loss: nan Test Loss: 5.3845263
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 2.2751762866973877
Epoch: 76, Steps: 4 | Train Loss: 0.3516887 Vali Loss: nan Test Loss: 5.3697510
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 2.446756601333618
Epoch: 77, Steps: 4 | Train Loss: 0.3587708 Vali Loss: nan Test Loss: 5.4009128
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 2.289614200592041
Epoch: 78, Steps: 4 | Train Loss: 0.3463862 Vali Loss: nan Test Loss: 5.3639746
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 2.3610050678253174
Epoch: 79, Steps: 4 | Train Loss: 0.3532448 Vali Loss: nan Test Loss: 5.4001164
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.3583669662475586
Epoch: 80, Steps: 4 | Train Loss: 0.3489196 Vali Loss: nan Test Loss: 5.3682303
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 2.60976243019104
Epoch: 81, Steps: 4 | Train Loss: 0.3488450 Vali Loss: nan Test Loss: 5.3648901
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.2743611335754395
Epoch: 82, Steps: 4 | Train Loss: 0.3468328 Vali Loss: nan Test Loss: 5.3809977
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 2.3050661087036133
Epoch: 83, Steps: 4 | Train Loss: 0.3548283 Vali Loss: nan Test Loss: 5.3734312
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 2.316659688949585
Epoch: 84, Steps: 4 | Train Loss: 0.3561485 Vali Loss: nan Test Loss: 5.3903685
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 2.2086281776428223
Epoch: 85, Steps: 4 | Train Loss: 0.3527814 Vali Loss: nan Test Loss: 5.3762016
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 2.3686363697052
Epoch: 86, Steps: 4 | Train Loss: 0.3677712 Vali Loss: nan Test Loss: 5.3918757
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.3064661026000977
Epoch: 87, Steps: 4 | Train Loss: 0.3442873 Vali Loss: nan Test Loss: 5.3928947
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 2.421372652053833
Epoch: 88, Steps: 4 | Train Loss: 0.3572389 Vali Loss: nan Test Loss: 5.3882031
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.3118832111358643
Epoch: 89, Steps: 4 | Train Loss: 0.3437478 Vali Loss: nan Test Loss: 5.3658028
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 2.3057093620300293
Epoch: 90, Steps: 4 | Train Loss: 0.3459376 Vali Loss: nan Test Loss: 5.3869944
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 2.2545390129089355
Epoch: 91, Steps: 4 | Train Loss: 0.3405566 Vali Loss: nan Test Loss: 5.3816943
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 2.090169668197632
Epoch: 92, Steps: 4 | Train Loss: 0.3508402 Vali Loss: nan Test Loss: 5.3751702
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.2163195610046387
Epoch: 93, Steps: 4 | Train Loss: 0.3362837 Vali Loss: nan Test Loss: 5.3911567
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 2.3821609020233154
Epoch: 94, Steps: 4 | Train Loss: 0.3570458 Vali Loss: nan Test Loss: 5.3726840
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.3763062953948975
Epoch: 95, Steps: 4 | Train Loss: 0.3437863 Vali Loss: nan Test Loss: 5.3663135
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 2.5366463661193848
Epoch: 96, Steps: 4 | Train Loss: 0.3550041 Vali Loss: nan Test Loss: 5.3756504
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.6696324348449707
Epoch: 97, Steps: 4 | Train Loss: 0.3486481 Vali Loss: nan Test Loss: 5.3817272
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 2.417894124984741
Epoch: 98, Steps: 4 | Train Loss: 0.3544399 Vali Loss: nan Test Loss: 5.3979788
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 2.982945680618286
Epoch: 99, Steps: 4 | Train Loss: 0.3479336 Vali Loss: nan Test Loss: 5.4011278
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 2.3471388816833496
Epoch: 100, Steps: 4 | Train Loss: 0.3544691 Vali Loss: nan Test Loss: 5.3823724
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : ili_36_60_Informer_custom_ftM_sl36_ll18_pl60_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 134
mse:5.386150360107422, mae:1.6109386682510376, rse:1.1089811325073242
