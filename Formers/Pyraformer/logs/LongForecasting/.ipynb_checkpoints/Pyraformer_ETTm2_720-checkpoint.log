[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=16, covariate_size=4, d_bottleneck=64, d_inner_hid=512, d_k=64, d_model=256, d_v=64, data='ETTm2', data_path='ETTm2.csv', dec_in=7, decoder='FC', dropout=0.2, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=720, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 7880832
train 33745
test 10801
[ Epoch 1 ]
  - (Training) MSE:  0.36017elapse: 0.741 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 0, mse:4.015608310699463, mae:1.5381832122802734, rmse:2.0038983821868896, mape:13.129142761230469, mspe:33909.5625
[ Epoch 2 ]
  - (Training) MSE:  0.25162elapse: 0.751 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 1, mse:3.6687166690826416, mae:1.44808828830719, rmse:1.9153894186019897, mape:12.755773544311523, mspe:32135.4921875
[ Epoch 3 ]
  - (Training) MSE:  0.24309elapse: 0.735 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 2, mse:3.7924704551696777, mae:1.4769206047058105, rmse:1.947426676750183, mape:13.162854194641113, mspe:33806.7890625
[ Epoch 4 ]
  - (Training) MSE:  0.24240elapse: 0.744 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 3, mse:3.844184637069702, mae:1.4901379346847534, rmse:1.9606592655181885, mape:13.206254959106445, mspe:34132.84375
[ Epoch 5 ]
  - (Training) MSE:  0.24212elapse: 0.721 min
(10801, 720, 7)
test shape:(10801, 720, 7)
Epoch 4, mse:3.663766384124756, mae:1.4479362964630127, rmse:1.914096713066101, mape:12.97342300415039, mspe:32732.5703125
Iteration best metrics: [3.663766384124756, 1.4479362964630127, 1.914096713066101, 12.97342300415039, 32732.5703125]
Average Metrics: [3.66376638e+00 1.44793630e+00 1.91409671e+00 1.29734230e+01
 3.27325703e+04]
