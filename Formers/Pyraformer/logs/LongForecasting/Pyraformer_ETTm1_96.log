[Info] parameters: Namespace(CSCM='Bottleneck_Construct', batch_size=32, covariate_size=4, d_bottleneck=64, d_inner_hid=512, d_k=64, d_model=256, d_v=64, data='ETTm1', data_path='ETTm1.csv', dec_in=7, decoder='FC', dropout=0.2, embed_type='DataEmbedding', enc_in=7, epoch=5, eval=False, hard_sample_mining=False, inner_size=3, input_size=96, inverse=False, iter_num=1, lr=0.0001, lr_step=0.1, model='Pyraformer', n_head=6, n_layer=4, predict_step=96, pretrain=False, root_path='../dataset/', seq_num=1, truncate=False, use_tvm=False, window_size=[4, 4, 4])
[Info] Number of parameters: 3408000
train 34369
test 11425
[ Epoch 1 ]
  - (Training) MSE:  0.44169elapse: 0.384 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 0, mse:0.5285163521766663, mae:0.5038328766822815, rmse:0.7269912958145142, mape:2.536599636077881, mspe:398.06536865234375
[ Epoch 2 ]
  - (Training) MSE:  0.31286elapse: 0.380 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 1, mse:0.5929068326950073, mae:0.5380881428718567, rmse:0.7700044512748718, mape:2.6503546237945557, mspe:451.2283630371094
[ Epoch 3 ]
  - (Training) MSE:  0.30595elapse: 0.380 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 2, mse:0.586717426776886, mae:0.5324074625968933, rmse:0.7659748196601868, mape:2.6155378818511963, mspe:417.86944580078125
[ Epoch 4 ]
  - (Training) MSE:  0.30457elapse: 0.381 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 3, mse:0.5811382532119751, mae:0.5305132269859314, rmse:0.7623242735862732, mape:2.61301326751709, mspe:415.50665283203125
[ Epoch 5 ]
  - (Training) MSE:  0.30440elapse: 0.379 min
(11425, 96, 7)
test shape:(11425, 96, 7)
Epoch 4, mse:0.5851213932037354, mae:0.5314383506774902, rmse:0.7649322748184204, mape:2.610037326812744, mspe:420.63177490234375
Iteration best metrics: [0.5285163521766663, 0.5038328766822815, 0.7269912958145142, 2.536599636077881, 398.06536865234375]
Average Metrics: [  0.52851635   0.50383288   0.7269913    2.53659964 398.06536865]
