Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=256, d_layers=1, d_model=128, data='custom', data_path='weather.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.2, e_layers=3, embed='timeF', embed_type=0, enc_in=21, factor=1, fc_dropout=0.2, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', mode_select='random', model='PatchTSFL', model_id='weather_336random_128', modes=128, moving_avg=25, n_heads=8, num_workers=0, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=96, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
fourier enhanced block used!
modes=128, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
>>>>>>>start training : weather_336random_128_PatchTSFL_custom_ftM_sl336_ll48_pl96_dm128_nh8_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36456
val 5175
test 10444
	iters: 100, epoch: 1 | loss: 0.5419444
	speed: 0.2050s/iter; left time: 5801.7605s
	iters: 200, epoch: 1 | loss: 0.7564550
	speed: 0.2062s/iter; left time: 5814.9116s
Epoch: 1 cost time: 58.557374238967896
Epoch: 1, Steps: 284 | Train Loss: 0.6659336 Vali Loss: 0.6171402 Test Loss: 0.2715832
Validation loss decreased (inf --> 0.617140).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4403339
	speed: 0.4133s/iter; left time: 11579.5481s
	iters: 200, epoch: 2 | loss: 0.3639933
	speed: 0.2064s/iter; left time: 5762.0777s
Epoch: 2 cost time: 58.538787603378296
Epoch: 2, Steps: 284 | Train Loss: 0.5093481 Vali Loss: 0.4267021 Test Loss: 0.1679470
Validation loss decreased (0.617140 --> 0.426702).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.4345427
	speed: 0.4136s/iter; left time: 11471.4617s
	iters: 200, epoch: 3 | loss: 0.3279597
	speed: 0.2064s/iter; left time: 5702.8123s
Epoch: 3 cost time: 58.544105529785156
Epoch: 3, Steps: 284 | Train Loss: 0.4549947 Vali Loss: 0.4067653 Test Loss: 0.1621469
Validation loss decreased (0.426702 --> 0.406765).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.3515893
	speed: 0.4134s/iter; left time: 11346.6528s
	iters: 200, epoch: 4 | loss: 0.4066059
	speed: 0.2063s/iter; left time: 5642.2422s
Epoch: 4 cost time: 58.537392377853394
Epoch: 4, Steps: 284 | Train Loss: 0.4438226 Vali Loss: 0.3966025 Test Loss: 0.1578413
Validation loss decreased (0.406765 --> 0.396602).  Saving model ...
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.3098150
	speed: 0.4133s/iter; left time: 11226.1899s
